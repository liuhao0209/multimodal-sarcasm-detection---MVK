
epoch: 5 train_loss=0.3066 train_acc=0.8433 valid_loss=0.3472 valid_acc=0.8193
epoch: 6 train_loss=0.2963 train_acc=0.8482 valid_loss=0.3398 valid_acc=0.8274
epoch: 7 train_loss=0.2909 train_acc=0.8527 valid_loss=0.3424 valid_acc=0.8250
epoch: 8 train_loss=0.2832 train_acc=0.8556 valid_loss=0.3417 valid_acc=0.8173
epoch: 9 train_loss=0.2777 train_acc=0.8590 valid_loss=0.3496 valid_acc=0.8185
epoch: 10 train_loss=0.2717 train_acc=0.8629 valid_loss=0.3367 valid_acc=0.8218
epoch: 11 train_loss=0.2669 train_acc=0.8656 valid_loss=0.3569 valid_acc=0.8153
epoch: 12 train_loss=0.2594 train_acc=0.8682 valid_loss=0.3441 valid_acc=0.8270
epoch: 13 train_loss=0.2539 train_acc=0.8729 valid_loss=0.3539 valid_acc=0.8287
epoch: 14 train_loss=0.2474 train_acc=0.8765 valid_loss=0.3559 valid_acc=0.8197
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=15 loss=0.31521 accuracy=0.8413 Pre=0.7637 Rec=0.8919 F-score=0.8228 Pre_macro=0.8387 Rec_macro=0.8488 F-score_macro=0.8396
start_local_time: 2023-06-01-13-40 run over time: 2023-06-01-14-47 ---------------this program run over----------------
learning rate=0.00015 | fc dropout=0.2 |  weight decay=1e-65
learning rate=0.00015 | fc dropout=0.2 |  weight decay=1e-65
epoch: 0 train_loss=0.5360 train_acc=0.6285 valid_loss=0.4604 valid_acc=0.7337
epoch: 1 train_loss=0.4057 train_acc=0.7734 valid_loss=0.3889 valid_acc=0.7942
learning rate=0.00015 | fc dropout=0.2 |  weight decay=1e-65
learning rate=0.00015 | fc dropout=0.2 |  weight decay=1e-65
learning rate=0.00015 | fc dropout=0.2 |  weight decay=1e-65
epoch: 0 train_loss=0.5303 train_acc=0.6426 valid_loss=0.4528 valid_acc=0.7385
epoch: 1 train_loss=0.4098 train_acc=0.7710 valid_loss=0.3966 valid_acc=0.7816
epoch: 2 train_loss=0.3655 train_acc=0.8023 valid_loss=0.3715 valid_acc=0.8096
epoch: 3 train_loss=0.3376 train_acc=0.8231 valid_loss=0.3572 valid_acc=0.8145
epoch: 4 train_loss=0.3205 train_acc=0.8336 valid_loss=0.3446 valid_acc=0.8226
epoch: 5 train_loss=0.3098 train_acc=0.8404 valid_loss=0.3392 valid_acc=0.8222
epoch: 6 train_loss=0.2982 train_acc=0.8479 valid_loss=0.3405 valid_acc=0.8226
epoch: 7 train_loss=0.2920 train_acc=0.8517 valid_loss=0.3408 valid_acc=0.8132
epoch: 8 train_loss=0.2853 train_acc=0.8565 valid_loss=0.3402 valid_acc=0.8230
epoch: 9 train_loss=0.2740 train_acc=0.8619 valid_loss=0.3302 valid_acc=0.8262
epoch: 10 train_loss=0.2714 train_acc=0.8624 valid_loss=0.3380 valid_acc=0.8299
epoch: 11 train_loss=0.2630 train_acc=0.8673 valid_loss=0.3310 valid_acc=0.8258
epoch: 12 train_loss=0.2584 train_acc=0.8717 valid_loss=0.3450 valid_acc=0.8323
epoch: 13 train_loss=0.2513 train_acc=0.8758 valid_loss=0.3325 valid_acc=0.8226
epoch: 14 train_loss=0.2450 train_acc=0.8787 valid_loss=0.3504 valid_acc=0.8222
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=15 loss=0.30109 accuracy=0.8519 Pre=0.8342 Rec=0.8006 F-score=0.8170 Pre_macro=0.8488 Rec_macro=0.8443 F-score_macro=0.8463
start_local_time: 2023-06-01-20-58 run over time: 2023-06-01-21-49 ---------------this program run over----------------
learning rate=0.00015 | fc dropout=0.2 |  weight decay=1e-65
epoch: 0 train_loss=0.5276 train_acc=0.6388 valid_loss=0.4622 valid_acc=0.7357
epoch: 1 train_loss=0.4023 train_acc=0.7771 valid_loss=0.4018 valid_acc=0.7877
epoch: 2 train_loss=0.3605 train_acc=0.8080 valid_loss=0.3637 valid_acc=0.8128
epoch: 3 train_loss=0.3340 train_acc=0.8240 valid_loss=0.3535 valid_acc=0.8169
epoch: 4 train_loss=0.3167 train_acc=0.8353 valid_loss=0.3423 valid_acc=0.8234
epoch: 5 train_loss=0.3046 train_acc=0.8402 valid_loss=0.3531 valid_acc=0.8266
epoch: 6 train_loss=0.2958 train_acc=0.8479 valid_loss=0.3454 valid_acc=0.8287
epoch: 7 train_loss=0.2936 train_acc=0.8505 valid_loss=0.3358 valid_acc=0.8279
epoch: 8 train_loss=0.2820 train_acc=0.8567 valid_loss=0.3362 valid_acc=0.8169
epoch: 9 train_loss=0.2771 train_acc=0.8568 valid_loss=0.3371 valid_acc=0.8238
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.30041 accuracy=0.8547 Pre=0.8113 Rec=0.8448 F-score=0.8277 Pre_macro=0.8494 Rec_macro=0.8532 F-score_macro=0.8511
start_local_time: 2023-06-02-00-37 run over time: 2023-06-02-01-16 ---------------this program run over----------------
learning rate=0.00015 | fc dropout=0.2 |  weight decay=1e-65
learning rate=0.00015 | fc dropout=0.2 |  weight decay=1e-65
epoch: 0 train_loss=0.5312 train_acc=0.6405 valid_loss=0.4460 valid_acc=0.7495
epoch: 1 train_loss=0.3996 train_acc=0.7781 valid_loss=0.3919 valid_acc=0.7893
learning rate=0.00015 | fc dropout=0.2 |  weight decay=1e-65
epoch: 0 train_loss=0.5230 train_acc=0.6514 valid_loss=0.4427 valid_acc=0.7548
epoch: 1 train_loss=0.3962 train_acc=0.7800 valid_loss=0.3891 valid_acc=0.7905
epoch: 2 train_loss=0.3570 train_acc=0.8110 valid_loss=0.3650 valid_acc=0.8140
epoch: 3 train_loss=0.3359 train_acc=0.8239 valid_loss=0.3607 valid_acc=0.8067
epoch: 4 train_loss=0.3210 train_acc=0.8336 valid_loss=0.3471 valid_acc=0.8234
epoch: 5 train_loss=0.3068 train_acc=0.8416 valid_loss=0.3463 valid_acc=0.8205
epoch: 6 train_loss=0.2978 train_acc=0.8466 valid_loss=0.3427 valid_acc=0.8124
epoch: 7 train_loss=0.2913 train_acc=0.8512 valid_loss=0.3356 valid_acc=0.8185
epoch: 8 train_loss=0.2833 train_acc=0.8559 valid_loss=0.3499 valid_acc=0.8189
epoch: 9 train_loss=0.2769 train_acc=0.8606 valid_loss=0.3292 valid_acc=0.8250
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.29112 accuracy=0.8567 Pre=0.8082 Rec=0.8566 F-score=0.8317 Pre_macro=0.8514 Rec_macro=0.8567 F-score_macro=0.8535
start_local_time: 2023-06-02-15-53 run over time: 2023-06-02-16-32 ---------------this program run over----------------
learning rate=0.00015 | fc dropout=0.22 |  weight decay=1e-65
epoch: 0 train_loss=0.5368 train_acc=0.6363 valid_loss=0.4586 valid_acc=0.7337
epoch: 1 train_loss=0.4078 train_acc=0.7730 valid_loss=0.3889 valid_acc=0.7921
epoch: 2 train_loss=0.3588 train_acc=0.8090 valid_loss=0.3636 valid_acc=0.8104
epoch: 3 train_loss=0.3337 train_acc=0.8276 valid_loss=0.3638 valid_acc=0.8136
epoch: 4 train_loss=0.3176 train_acc=0.8350 valid_loss=0.3422 valid_acc=0.8189
epoch: 5 train_loss=0.3114 train_acc=0.8402 valid_loss=0.3393 valid_acc=0.8250
epoch: 6 train_loss=0.2977 train_acc=0.8486 valid_loss=0.3369 valid_acc=0.8258
epoch: 7 train_loss=0.2918 train_acc=0.8521 valid_loss=0.3390 valid_acc=0.8197
epoch: 8 train_loss=0.2830 train_acc=0.8558 valid_loss=0.3402 valid_acc=0.8234
epoch: 9 train_loss=0.2790 train_acc=0.8609 valid_loss=0.3396 valid_acc=0.8197
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.30238 accuracy=0.8515 Pre=0.7865 Rec=0.8792 F-score=0.8302 Pre_macro=0.8469 Rec_macro=0.8556 F-score_macro=0.8491
start_local_time: 2023-06-02-16-48 run over time: 2023-06-02-17-23 ---------------this program run over----------------
learning rate=0.00015 | fc dropout=0.3 |  weight decay=1e-65
epoch: 0 train_loss=0.5261 train_acc=0.6410 valid_loss=0.4513 valid_acc=0.7446
epoch: 1 train_loss=0.4035 train_acc=0.7732 valid_loss=0.3951 valid_acc=0.7824
epoch: 2 train_loss=0.3625 train_acc=0.8072 valid_loss=0.3685 valid_acc=0.8059
epoch: 3 train_loss=0.3339 train_acc=0.8270 valid_loss=0.3492 valid_acc=0.8214
epoch: 4 train_loss=0.3167 train_acc=0.8358 valid_loss=0.3415 valid_acc=0.8226
epoch: 5 train_loss=0.3070 train_acc=0.8402 valid_loss=0.3446 valid_acc=0.8145
epoch: 6 train_loss=0.3001 train_acc=0.8458 valid_loss=0.3414 valid_acc=0.8197
epoch: 7 train_loss=0.2886 train_acc=0.8532 valid_loss=0.3378 valid_acc=0.8226
epoch: 8 train_loss=0.2833 train_acc=0.8578 valid_loss=0.3438 valid_acc=0.8238
epoch: 9 train_loss=0.2807 train_acc=0.8586 valid_loss=0.3324 valid_acc=0.8242
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.29633 accuracy=0.8588 Pre=0.8013 Rec=0.8752 F-score=0.8366 Pre_macro=0.8537 Rec_macro=0.8612 F-score_macro=0.8561
start_local_time: 2023-06-02-17-30 run over time: 2023-06-02-18-09 ---------------this program run over----------------

learning rate=0.00015 | fc dropout=0.3 |  weight decay=1e-65
epoch: 0 train_loss=0.5303 train_acc=0.6403 valid_loss=0.4440 valid_acc=0.7527
epoch: 1 train_loss=0.3956 train_acc=0.7789 valid_loss=0.4109 valid_acc=0.7771
epoch: 2 train_loss=0.3556 train_acc=0.8121 valid_loss=0.3552 valid_acc=0.8149
epoch: 3 train_loss=0.3255 train_acc=0.8315 valid_loss=0.3482 valid_acc=0.8230
epoch: 4 train_loss=0.3134 train_acc=0.8366 valid_loss=0.3438 valid_acc=0.8246
epoch: 5 train_loss=0.3038 train_acc=0.8424 valid_loss=0.3373 valid_acc=0.8258
epoch: 6 train_loss=0.2946 train_acc=0.8479 valid_loss=0.3536 valid_acc=0.8270
epoch: 7 train_loss=0.2882 train_acc=0.8526 valid_loss=0.3515 valid_acc=0.8274
epoch: 8 train_loss=0.2811 train_acc=0.8573 valid_loss=0.3344 valid_acc=0.8218
epoch: 9 train_loss=0.2778 train_acc=0.8607 valid_loss=0.3406 valid_acc=0.8177
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.30271 accuracy=0.8506 Pre=0.7866 Rec=0.8762 F-score=0.8290 Pre_macro=0.8459 Rec_macro=0.8544 F-score_macro=0.8482
start_local_time: 2023-06-02-22-16 run over time: 2023-06-02-22-57 ---------------this program run over----------------
learning rate=0.00015 | fc dropout=0.3 |  weight decay=1e-65
epoch: 0 train_loss=0.5203 train_acc=0.6481 valid_loss=0.4400 valid_acc=0.7515
epoch: 1 train_loss=0.3993 train_acc=0.7763 valid_loss=0.3916 valid_acc=0.7909
epoch: 2 train_loss=0.3617 train_acc=0.8065 valid_loss=0.3608 valid_acc=0.8120
epoch: 3 train_loss=0.3361 train_acc=0.8247 valid_loss=0.3533 valid_acc=0.8226
epoch: 4 train_loss=0.3174 train_acc=0.8348 valid_loss=0.3488 valid_acc=0.8226
epoch: 5 train_loss=0.3051 train_acc=0.8436 valid_loss=0.3627 valid_acc=0.8181
epoch: 6 train_loss=0.3017 train_acc=0.8418 valid_loss=0.3359 valid_acc=0.8274
epoch: 7 train_loss=0.2889 train_acc=0.8531 valid_loss=0.3347 valid_acc=0.8250
epoch: 8 train_loss=0.2833 train_acc=0.8548 valid_loss=0.3414 valid_acc=0.8124
epoch: 9 train_loss=0.2770 train_acc=0.8593 valid_loss=0.3334 valid_acc=0.8254
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.29368 accuracy=0.8551 Pre=0.8013 Rec=0.8635 F-score=0.8312 Pre_macro=0.8498 Rec_macro=0.8563 F-score_macro=0.8521
start_local_time: 2023-06-02-22-59 run over time: 2023-06-02-23-34 ---------------this program run over----------------
learning rate=0.00015 | fc dropout=0.35 |  weight decay=1e-65
epoch: 0 train_loss=0.5269 train_acc=0.6457 valid_loss=0.4551 valid_acc=0.7442
epoch: 1 train_loss=0.4075 train_acc=0.7746 valid_loss=0.3825 valid_acc=0.7917
epoch: 2 train_loss=0.3553 train_acc=0.8134 valid_loss=0.3659 valid_acc=0.8153
epoch: 3 train_loss=0.3355 train_acc=0.8272 valid_loss=0.3592 valid_acc=0.8149
epoch: 4 train_loss=0.3186 train_acc=0.8349 valid_loss=0.3475 valid_acc=0.8165
epoch: 5 train_loss=0.3086 train_acc=0.8412 valid_loss=0.3431 valid_acc=0.8205
epoch: 6 train_loss=0.2971 train_acc=0.8481 valid_loss=0.3424 valid_acc=0.8238
epoch: 7 train_loss=0.2929 train_acc=0.8515 valid_loss=0.3450 valid_acc=0.8242
epoch: 8 train_loss=0.2872 train_acc=0.8531 valid_loss=0.3447 valid_acc=0.8238
epoch: 9 train_loss=0.2792 train_acc=0.8589 valid_loss=0.3459 valid_acc=0.8246
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.30633 accuracy=0.8413 Pre=0.8276 Rec=0.7780 F-score=0.8020 Pre_macro=0.8388 Rec_macro=0.8319 F-score_macro=0.8348
start_local_time: 2023-06-02-23-40 run over time: 2023-06-03-00-16 ---------------this program run over----------------
learning rate=0.00015 | fc dropout=0.5 |  weight decay=1e-65
epoch: 0 train_loss=0.5331 train_acc=0.6400 valid_loss=0.4565 valid_acc=0.7369
learning rate=0.00015 | fc dropout=0.5 |  weight decay=1e-65
epoch: 0 train_loss=0.5300 train_acc=0.6369 valid_loss=0.4496 valid_acc=0.7430
epoch: 1 train_loss=0.3955 train_acc=0.7826 valid_loss=0.3903 valid_acc=0.7946
epoch: 2 train_loss=0.3605 train_acc=0.8085 valid_loss=0.4022 valid_acc=0.7795
epoch: 3 train_loss=0.3331 train_acc=0.8277 valid_loss=0.3575 valid_acc=0.8189
epoch: 4 train_loss=0.3190 train_acc=0.8342 valid_loss=0.3900 valid_acc=0.7848
epoch: 5 train_loss=0.3084 train_acc=0.8395 valid_loss=0.3687 valid_acc=0.7994
epoch: 6 train_loss=0.2975 train_acc=0.8471 valid_loss=0.3472 valid_acc=0.8169
epoch: 7 train_loss=0.2889 train_acc=0.8546 valid_loss=0.3675 valid_acc=0.8019
epoch: 8 train_loss=0.2841 train_acc=0.8577 valid_loss=0.3417 valid_acc=0.8242
epoch: 9 train_loss=0.2764 train_acc=0.8597 valid_loss=0.3378 valid_acc=0.8193
learning rate=0.00015 | fc dropout=0.5 |  weight decay=1e-05
epoch: 0 train_loss=0.5344 train_acc=0.6320 valid_loss=0.4545 valid_acc=0.7426
epoch: 1 train_loss=0.4186 train_acc=0.7633 valid_loss=0.4097 valid_acc=0.7734
epoch: 2 train_loss=0.3634 train_acc=0.8050 valid_loss=0.3643 valid_acc=0.8076
epoch: 3 train_loss=0.3399 train_acc=0.8213 valid_loss=0.3610 valid_acc=0.8136
epoch: 4 train_loss=0.3249 train_acc=0.8323 valid_loss=0.3512 valid_acc=0.8177
epoch: 5 train_loss=0.3120 train_acc=0.8416 valid_loss=0.3448 valid_acc=0.8181
epoch: 6 train_loss=0.3045 train_acc=0.8434 valid_loss=0.3541 valid_acc=0.8230
epoch: 7 train_loss=0.2981 train_acc=0.8497 valid_loss=0.3409 valid_acc=0.8189
epoch: 8 train_loss=0.2903 train_acc=0.8537 valid_loss=0.3440 valid_acc=0.8210
epoch: 9 train_loss=0.2875 train_acc=0.8544 valid_loss=0.3431 valid_acc=0.8145
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.30432 accuracy=0.8543 Pre=0.7913 Rec=0.8792 F-score=0.8329 Pre_macro=0.8495 Rec_macro=0.8580 F-score_macro=0.8519
start_local_time: 2023-06-03-04-50 run over time: 2023-06-03-05-59 ---------------this program run over----------------
learning rate=0.00016 | fc dropout=0.5 |  weight decay=1e-65
epoch: 0 train_loss=0.5227 train_acc=0.6500 valid_loss=0.4445 valid_acc=0.7527
epoch: 1 train_loss=0.4059 train_acc=0.7766 valid_loss=0.3926 valid_acc=0.7873
epoch: 2 train_loss=0.3637 train_acc=0.8070 valid_loss=0.3691 valid_acc=0.8108
epoch: 3 train_loss=0.3391 train_acc=0.8219 valid_loss=0.3550 valid_acc=0.8173
epoch: 4 train_loss=0.3213 train_acc=0.8332 valid_loss=0.3483 valid_acc=0.8230
epoch: 5 train_loss=0.3083 train_acc=0.8421 valid_loss=0.3404 valid_acc=0.8197
epoch: 6 train_loss=0.3012 train_acc=0.8457 valid_loss=0.3433 valid_acc=0.8145
epoch: 7 train_loss=0.2931 train_acc=0.8500 valid_loss=0.3414 valid_acc=0.8210
epoch: 8 train_loss=0.2880 train_acc=0.8538 valid_loss=0.3383 valid_acc=0.8193
epoch: 9 train_loss=0.2812 train_acc=0.8593 valid_loss=0.3312 valid_acc=0.8218
learning rate=0.00016 | fc dropout=0.5 |  weight decay=1e-05
epoch: 0 train_loss=0.5304 train_acc=0.6361 valid_loss=0.4531 valid_acc=0.7475
epoch: 1 train_loss=0.4111 train_acc=0.7706 valid_loss=0.3915 valid_acc=0.7893
epoch: 2 train_loss=0.3612 train_acc=0.8094 valid_loss=0.3611 valid_acc=0.8132
epoch: 3 train_loss=0.3329 train_acc=0.8262 valid_loss=0.3446 valid_acc=0.8185
epoch: 4 train_loss=0.3207 train_acc=0.8343 valid_loss=0.3597 valid_acc=0.8165
epoch: 5 train_loss=0.3099 train_acc=0.8411 valid_loss=0.3684 valid_acc=0.8092
epoch: 6 train_loss=0.3003 train_acc=0.8464 valid_loss=0.3598 valid_acc=0.8140
epoch: 7 train_loss=0.2939 train_acc=0.8515 valid_loss=0.3405 valid_acc=0.8270
epoch: 8 train_loss=0.2863 train_acc=0.8550 valid_loss=0.3779 valid_acc=0.7950
epoch: 9 train_loss=0.2806 train_acc=0.8589 valid_loss=0.3641 valid_acc=0.8177
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.32464 accuracy=0.8470 Pre=0.7723 Rec=0.8929 F-score=0.8282 Pre_macro=0.8438 Rec_macro=0.8538 F-score_macro=0.8452
start_local_time: 2023-06-03-14-39 run over time: 2023-06-03-15-52 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65
epoch: 0 train_loss=0.5094 train_acc=0.6648 valid_loss=0.4453 valid_acc=0.7511
epoch: 1 train_loss=0.3931 train_acc=0.7832 valid_loss=0.3802 valid_acc=0.7986
epoch: 2 train_loss=0.3481 train_acc=0.8161 valid_loss=0.3605 valid_acc=0.8136
epoch: 3 train_loss=0.3251 train_acc=0.8306 valid_loss=0.3468 valid_acc=0.8177
epoch: 4 train_loss=0.3122 train_acc=0.8378 valid_loss=0.3606 valid_acc=0.8173
epoch: 5 train_loss=0.3008 train_acc=0.8461 valid_loss=0.3386 valid_acc=0.8250
epoch: 6 train_loss=0.2906 train_acc=0.8519 valid_loss=0.3318 valid_acc=0.8242
epoch: 7 train_loss=0.2853 train_acc=0.8555 valid_loss=0.3361 valid_acc=0.8283
epoch: 8 train_loss=0.2752 train_acc=0.8603 valid_loss=0.3348 valid_acc=0.8299
epoch: 9 train_loss=0.2692 train_acc=0.8661 valid_loss=0.3502 valid_acc=0.8124
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-05
epoch: 0 train_loss=0.5134 train_acc=0.6596 valid_loss=0.4416 valid_acc=0.7540
epoch: 1 train_loss=0.3997 train_acc=0.7772 valid_loss=0.3873 valid_acc=0.7970
epoch: 2 train_loss=0.3493 train_acc=0.8162 valid_loss=0.3505 valid_acc=0.8157
epoch: 3 train_loss=0.3242 train_acc=0.8316 valid_loss=0.3432 valid_acc=0.8214
epoch: 4 train_loss=0.3093 train_acc=0.8430 valid_loss=0.3369 valid_acc=0.8246
epoch: 5 train_loss=0.3022 train_acc=0.8465 valid_loss=0.3338 valid_acc=0.8226
epoch: 6 train_loss=0.2944 train_acc=0.8502 valid_loss=0.3369 valid_acc=0.8238
epoch: 7 train_loss=0.2836 train_acc=0.8577 valid_loss=0.3419 valid_acc=0.8287
epoch: 8 train_loss=0.2775 train_acc=0.8619 valid_loss=0.3342 valid_acc=0.8287
epoch: 9 train_loss=0.2718 train_acc=0.8654 valid_loss=0.3378 valid_acc=0.8230
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.29367 accuracy=0.8608 Pre=0.8211 Rec=0.8477 F-score=0.8342 Pre_macro=0.8557 Rec_macro=0.8589 F-score_macro=0.8571
start_local_time: 2023-06-03-16-57 run over time: 2023-06-03-17-55 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65
epoch: 0 train_loss=0.5125 train_acc=0.6623 valid_loss=0.4226 valid_acc=0.7621
epoch: 1 train_loss=0.3795 train_acc=0.7942 valid_loss=0.3704 valid_acc=0.7994
epoch: 2 train_loss=0.3421 train_acc=0.8204 valid_loss=0.3509 valid_acc=0.8149
epoch: 3 train_loss=0.3198 train_acc=0.8335 valid_loss=0.3441 valid_acc=0.8140
epoch: 4 train_loss=0.3054 train_acc=0.8423 valid_loss=0.3429 valid_acc=0.8197
epoch: 5 train_loss=0.2994 train_acc=0.8457 valid_loss=0.3370 valid_acc=0.8274
epoch: 6 train_loss=0.2896 train_acc=0.8507 valid_loss=0.3363 valid_acc=0.8238
epoch: 7 train_loss=0.2820 train_acc=0.8566 valid_loss=0.3393 valid_acc=0.8258
epoch: 8 train_loss=0.2781 train_acc=0.8571 valid_loss=0.3326 valid_acc=0.8226
epoch: 9 train_loss=0.2693 train_acc=0.8638 valid_loss=0.3469 valid_acc=0.8157
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-05
epoch: 0 train_loss=0.5204 train_acc=0.6505 valid_loss=0.4464 valid_acc=0.7491
epoch: 1 train_loss=0.3991 train_acc=0.7797 valid_loss=0.3791 valid_acc=0.7998
epoch: 2 train_loss=0.3500 train_acc=0.8150 valid_loss=0.3570 valid_acc=0.8153
epoch: 3 train_loss=0.3268 train_acc=0.8309 valid_loss=0.3539 valid_acc=0.8136
epoch: 4 train_loss=0.3141 train_acc=0.8377 valid_loss=0.3642 valid_acc=0.8084
epoch: 5 train_loss=0.3090 train_acc=0.8414 valid_loss=0.3360 valid_acc=0.8254
epoch: 6 train_loss=0.2983 train_acc=0.8496 valid_loss=0.3339 valid_acc=0.8274
epoch: 7 train_loss=0.2898 train_acc=0.8533 valid_loss=0.3483 valid_acc=0.8246
epoch: 8 train_loss=0.2858 train_acc=0.8559 valid_loss=0.3431 valid_acc=0.8270
epoch: 9 train_loss=0.2784 train_acc=0.8601 valid_loss=0.3407 valid_acc=0.8258
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.30259 accuracy=0.8592 Pre=0.8025 Rec=0.8743 F-score=0.8369 Pre_macro=0.8540 Rec_macro=0.8614 F-score_macro=0.8565
start_local_time: 2023-06-03-18-07 run over time: 2023-06-03-19-07 ---------------this program run over----------------
learning rate=0.00025 | fc dropout=0.25 |  weight decay=1e-07
epoch: 0 train_loss=0.5491 train_acc=0.6057 valid_loss=0.4843 valid_acc=0.6987
epoch: 1 train_loss=0.4306 train_acc=0.7449 valid_loss=0.4155 valid_acc=0.7747
epoch: 2 train_loss=0.3748 train_acc=0.7882 valid_loss=0.3767 valid_acc=0.8019
epoch: 3 train_loss=0.3413 train_acc=0.8107 valid_loss=0.3578 valid_acc=0.8177
epoch: 4 train_loss=0.3226 train_acc=0.8223 valid_loss=0.3531 valid_acc=0.8230
epoch: 5 train_loss=0.3097 train_acc=0.8309 valid_loss=0.3488 valid_acc=0.8242
epoch: 6 train_loss=0.3009 train_acc=0.8358 valid_loss=0.3459 valid_acc=0.8242
epoch: 7 train_loss=0.2927 train_acc=0.8411 valid_loss=0.3439 valid_acc=0.8205
epoch: 8 train_loss=0.2863 train_acc=0.8453 valid_loss=0.3404 valid_acc=0.8254
epoch: 9 train_loss=0.2827 train_acc=0.8451 valid_loss=0.3409 valid_acc=0.8222
epoch: 10 train_loss=0.2770 train_acc=0.8489 valid_loss=0.3456 valid_acc=0.8210
epoch: 11 train_loss=0.2680 train_acc=0.8562 valid_loss=0.3469 valid_acc=0.8230
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=12 loss=0.29586 accuracy=0.8551 Pre=0.8335 Rec=0.8114 F-score=0.8223 Pre_macro=0.8516 Rec_macro=0.8486 F-score_macro=0.8500
start_local_time: 2023-06-03-22-20 run over time: 2023-06-03-22-59 ---------------this program run over----------------
learning rate=0.00025 | fc dropout=0.25 |  weight decay=0
epoch: 0 train_loss=0.5512 train_acc=0.6035 valid_loss=0.4780 valid_acc=0.7178
epoch: 1 train_loss=0.4327 train_acc=0.7424 valid_loss=0.4197 valid_acc=0.7674
epoch: 2 train_loss=0.3789 train_acc=0.7849 valid_loss=0.3814 valid_acc=0.8019
epoch: 3 train_loss=0.3452 train_acc=0.8089 valid_loss=0.3600 valid_acc=0.8189
epoch: 4 train_loss=0.3248 train_acc=0.8207 valid_loss=0.3501 valid_acc=0.8165
epoch: 5 train_loss=0.3119 train_acc=0.8292 valid_loss=0.3479 valid_acc=0.8214
epoch: 6 train_loss=0.3012 train_acc=0.8354 valid_loss=0.3505 valid_acc=0.8136
epoch: 7 train_loss=0.2930 train_acc=0.8408 valid_loss=0.3447 valid_acc=0.8210
epoch: 8 train_loss=0.2862 train_acc=0.8461 valid_loss=0.3519 valid_acc=0.8169
epoch: 9 train_loss=0.2794 train_acc=0.8501 valid_loss=0.3549 valid_acc=0.8173
epoch: 10 train_loss=0.2731 train_acc=0.8535 valid_loss=0.3554 valid_acc=0.8145
epoch: 11 train_loss=0.2677 train_acc=0.8570 valid_loss=0.3496 valid_acc=0.8189
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=12 loss=0.30188 accuracy=0.8498 Pre=0.8202 Rec=0.8153 F-score=0.8177 Pre_macro=0.8453 Rec_macro=0.8447 F-score_macro=0.8450
start_local_time: 2023-06-03-23-16 run over time: 2023-06-03-23-53 ---------------this program run over----------------
learning rate=0.00025 | fc dropout=0.25 |  weight decay=1e-65
learning rate=0.00025 | fc dropout=0.25 |  weight decay=1e-65
epoch: 0 train_loss=0.5502 train_acc=0.6071 valid_loss=0.4783 valid_acc=0.7113
epoch: 1 train_loss=0.4290 train_acc=0.7456 valid_loss=0.4154 valid_acc=0.7844
epoch: 2 train_loss=0.3729 train_acc=0.7900 valid_loss=0.3705 valid_acc=0.8108
epoch: 3 train_loss=0.3390 train_acc=0.8133 valid_loss=0.3563 valid_acc=0.8181
epoch: 4 train_loss=0.3211 train_acc=0.8238 valid_loss=0.3505 valid_acc=0.8177
epoch: 5 train_loss=0.3080 train_acc=0.8325 valid_loss=0.3540 valid_acc=0.8201
epoch: 6 train_loss=0.2997 train_acc=0.8369 valid_loss=0.3482 valid_acc=0.8238
epoch: 7 train_loss=0.2915 train_acc=0.8423 valid_loss=0.3526 valid_acc=0.8210
epoch: 8 train_loss=0.2837 train_acc=0.8462 valid_loss=0.3514 valid_acc=0.8218
epoch: 9 train_loss=0.2749 train_acc=0.8509 valid_loss=0.3490 valid_acc=0.8242
epoch: 10 train_loss=0.2676 train_acc=0.8562 valid_loss=0.3490 valid_acc=0.8262
epoch: 11 train_loss=0.2627 train_acc=0.8580 valid_loss=0.3540 valid_acc=0.8254
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=12 loss=0.30474 accuracy=0.8470 Pre=0.8195 Rec=0.8075 F-score=0.8135 Pre_macro=0.8427 Rec_macro=0.8411 F-score_macro=0.8419
start_local_time: 2023-06-08-17-52 run over time: 2023-06-08-18-38 ---------------this program run over----------------

learning rate=0.00025 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=3
epoch: 0 train_loss=0.4994 train_acc=0.6757 valid_loss=0.4242 valid_acc=0.7670
epoch: 1 train_loss=0.3791 train_acc=0.7952 valid_loss=0.3681 valid_acc=0.8071
epoch: 2 train_loss=0.3381 train_acc=0.8225 valid_loss=0.3528 valid_acc=0.8177
epoch: 3 train_loss=0.3188 train_acc=0.8357 valid_loss=0.3462 valid_acc=0.8222
epoch: 4 train_loss=0.3050 train_acc=0.8438 valid_loss=0.3449 valid_acc=0.8189
epoch: 5 train_loss=0.2954 train_acc=0.8503 valid_loss=0.3427 valid_acc=0.8222
epoch: 6 train_loss=0.2872 train_acc=0.8549 valid_loss=0.3427 valid_acc=0.8205
epoch: 7 train_loss=0.2803 train_acc=0.8587 valid_loss=0.3450 valid_acc=0.8210
epoch: 8 train_loss=0.2728 train_acc=0.8625 valid_loss=0.3475 valid_acc=0.8242
epoch: 9 train_loss=0.2654 train_acc=0.8678 valid_loss=0.3496 valid_acc=0.8270
epoch: 10 train_loss=0.2580 train_acc=0.8710 valid_loss=0.3550 valid_acc=0.8250
epoch: 11 train_loss=0.2514 train_acc=0.8763 valid_loss=0.3606 valid_acc=0.8189
epoch: 12 train_loss=0.2449 train_acc=0.8799 valid_loss=0.3622 valid_acc=0.8222
epoch: 13 train_loss=0.2391 train_acc=0.8810 valid_loss=0.3665 valid_acc=0.8258
epoch: 14 train_loss=0.2333 train_acc=0.8853 valid_loss=0.3742 valid_acc=0.8262
epoch: 15 train_loss=0.2264 train_acc=0.8894 valid_loss=0.3817 valid_acc=0.8279
epoch: 16 train_loss=0.2198 train_acc=0.8925 valid_loss=0.3921 valid_acc=0.8274
epoch: 17 train_loss=0.2145 train_acc=0.8955 valid_loss=0.4130 valid_acc=0.8116
epoch: 18 train_loss=0.2101 train_acc=0.8983 valid_loss=0.4124 valid_acc=0.8149
epoch: 19 train_loss=0.2019 train_acc=0.9045 valid_loss=0.4190 valid_acc=0.8136
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=20 loss=0.35374 accuracy=0.8531 Pre=0.8100 Rec=0.8418 F-score=0.8256 Pre_macro=0.8478 Rec_macro=0.8514 F-score_macro=0.8493
start_local_time: 2023-06-08-18-53 run over time: 2023-06-08-19-51 ---------------this program run over----------------
learning rate=0.00025 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=3
epoch: 0 train_loss=0.4539 train_acc=0.7240 valid_loss=0.3875 valid_acc=0.7937
epoch: 1 train_loss=0.3500 train_acc=0.8152 valid_loss=0.3554 valid_acc=0.8116
epoch: 2 train_loss=0.3207 train_acc=0.8339 valid_loss=0.3412 valid_acc=0.8201
epoch: 3 train_loss=0.3051 train_acc=0.8450 valid_loss=0.3374 valid_acc=0.8185
epoch: 4 train_loss=0.2940 train_acc=0.8518 valid_loss=0.3355 valid_acc=0.8189
epoch: 5 train_loss=0.2847 train_acc=0.8595 valid_loss=0.3382 valid_acc=0.8205
epoch: 6 train_loss=0.2762 train_acc=0.8626 valid_loss=0.3462 valid_acc=0.8149
epoch: 7 train_loss=0.2680 train_acc=0.8679 valid_loss=0.3526 valid_acc=0.8132
epoch: 8 train_loss=0.2606 train_acc=0.8718 valid_loss=0.3480 valid_acc=0.8181
epoch: 9 train_loss=0.2535 train_acc=0.8757 valid_loss=0.3563 valid_acc=0.8161
epoch: 10 train_loss=0.2454 train_acc=0.8792 valid_loss=0.3587 valid_acc=0.8153
epoch: 11 train_loss=0.2378 train_acc=0.8845 valid_loss=0.3634 valid_acc=0.8230
epoch: 12 train_loss=0.2310 train_acc=0.8882 valid_loss=0.3700 valid_acc=0.8218
epoch: 13 train_loss=0.2247 train_acc=0.8896 valid_loss=0.3746 valid_acc=0.8266
epoch: 14 train_loss=0.2161 train_acc=0.8954 valid_loss=0.3924 valid_acc=0.8185
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=15 loss=0.35835 accuracy=0.8490 Pre=0.7980 Rec=0.8497 F-score=0.8230 Pre_macro=0.8436 Rec_macro=0.8491 F-score_macro=0.8457
start_local_time: 2023-06-08-22-08 run over time: 2023-06-08-23-07 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-07 | Multi_Nums=3
epoch: 0 train_loss=0.5100 train_acc=0.6654 valid_loss=0.4412 valid_acc=0.7564
epoch: 1 train_loss=0.3898 train_acc=0.7846 valid_loss=0.3809 valid_acc=0.7994
epoch: 2 train_loss=0.3470 train_acc=0.8185 valid_loss=0.3614 valid_acc=0.8071
epoch: 3 train_loss=0.3236 train_acc=0.8312 valid_loss=0.3499 valid_acc=0.8157
epoch: 4 train_loss=0.3083 train_acc=0.8399 valid_loss=0.3452 valid_acc=0.8177
epoch: 5 train_loss=0.2982 train_acc=0.8476 valid_loss=0.3440 valid_acc=0.8181
epoch: 6 train_loss=0.2893 train_acc=0.8523 valid_loss=0.3435 valid_acc=0.8218
epoch: 7 train_loss=0.2807 train_acc=0.8593 valid_loss=0.3450 valid_acc=0.8230
epoch: 8 train_loss=0.2738 train_acc=0.8630 valid_loss=0.3491 valid_acc=0.8222
epoch: 9 train_loss=0.2662 train_acc=0.8673 valid_loss=0.3484 valid_acc=0.8234
epoch: 10 train_loss=0.2608 train_acc=0.8720 valid_loss=0.3523 valid_acc=0.8222
epoch: 11 train_loss=0.2542 train_acc=0.8755 valid_loss=0.3567 valid_acc=0.8189
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=12 loss=0.30411 accuracy=0.8584 Pre=0.8207 Rec=0.8409 F-score=0.8307 Pre_macro=0.8534 Rec_macro=0.8558 F-score_macro=0.8545
start_local_time: 2023-06-09-16-18 run over time: 2023-06-09-17-05 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-07 | Multi_Nums=3
epoch: 0 train_loss=0.5144 train_acc=0.6555 valid_loss=0.4402 valid_acc=0.7580
epoch: 1 train_loss=0.3892 train_acc=0.7859 valid_loss=0.3774 valid_acc=0.8002
epoch: 2 train_loss=0.3452 train_acc=0.8195 valid_loss=0.3574 valid_acc=0.8157
epoch: 3 train_loss=0.3220 train_acc=0.8312 valid_loss=0.3499 valid_acc=0.8165
epoch: 4 train_loss=0.3078 train_acc=0.8396 valid_loss=0.3465 valid_acc=0.8230
epoch: 5 train_loss=0.2970 train_acc=0.8474 valid_loss=0.3414 valid_acc=0.8238
epoch: 6 train_loss=0.2876 train_acc=0.8536 valid_loss=0.3432 valid_acc=0.8262
epoch: 7 train_loss=0.2798 train_acc=0.8595 valid_loss=0.3404 valid_acc=0.8254
epoch: 8 train_loss=0.2733 train_acc=0.8622 valid_loss=0.3440 valid_acc=0.8274
epoch: 9 train_loss=0.2654 train_acc=0.8669 valid_loss=0.3442 valid_acc=0.8287
epoch: 10 train_loss=0.2595 train_acc=0.8696 valid_loss=0.3476 valid_acc=0.8307
epoch: 11 train_loss=0.2540 train_acc=0.8739 valid_loss=0.3504 valid_acc=0.8307
epoch: 12 train_loss=0.2474 train_acc=0.8771 valid_loss=0.3560 valid_acc=0.8287
epoch: 13 train_loss=0.2411 train_acc=0.8803 valid_loss=0.3591 valid_acc=0.8258
epoch: 14 train_loss=0.2348 train_acc=0.8858 valid_loss=0.3673 valid_acc=0.8214
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=15 loss=0.31701 accuracy=0.8502 Pre=0.8222 Rec=0.8134 F-score=0.8178 Pre_macro=0.8459 Rec_macro=0.8448 F-score_macro=0.8453
start_local_time: 2023-06-09-19-18 run over time: 2023-06-09-20-09 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=3
epoch: 0 train_loss=0.5133 train_acc=0.6592 valid_loss=0.4401 valid_acc=0.7576
epoch: 1 train_loss=0.3870 train_acc=0.7891 valid_loss=0.3753 valid_acc=0.8059
epoch: 2 train_loss=0.3417 train_acc=0.8218 valid_loss=0.3558 valid_acc=0.8177
epoch: 3 train_loss=0.3198 train_acc=0.8322 valid_loss=0.3482 valid_acc=0.8169
epoch: 4 train_loss=0.3062 train_acc=0.8418 valid_loss=0.3446 valid_acc=0.8218
epoch: 5 train_loss=0.2966 train_acc=0.8490 valid_loss=0.3416 valid_acc=0.8222
epoch: 6 train_loss=0.2873 train_acc=0.8539 valid_loss=0.3427 valid_acc=0.8226
epoch: 7 train_loss=0.2802 train_acc=0.8579 valid_loss=0.3400 valid_acc=0.8262
epoch: 8 train_loss=0.2735 train_acc=0.8621 valid_loss=0.3399 valid_acc=0.8266
epoch: 9 train_loss=0.2675 train_acc=0.8659 valid_loss=0.3399 valid_acc=0.8279
epoch: 10 train_loss=0.2608 train_acc=0.8707 valid_loss=0.3403 valid_acc=0.8250
epoch: 11 train_loss=0.2557 train_acc=0.8736 valid_loss=0.3392 valid_acc=0.8331
epoch: 12 train_loss=0.2502 train_acc=0.8764 valid_loss=0.3391 valid_acc=0.8319
epoch: 13 train_loss=0.2442 train_acc=0.8801 valid_loss=0.3419 valid_acc=0.8319
epoch: 14 train_loss=0.2385 train_acc=0.8833 valid_loss=0.3426 valid_acc=0.8372
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=15 loss=0.29568 accuracy=0.8575 Pre=0.8179 Rec=0.8428 F-score=0.8302 Pre_macro=0.8524 Rec_macro=0.8554 F-score_macro=0.8538
start_local_time: 2023-06-09-20-29 run over time: 2023-06-09-21-21 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=3
epoch: 0 train_loss=0.5187 train_acc=0.6481 valid_loss=0.4303 valid_acc=0.7588
epoch: 1 train_loss=0.3804 train_acc=0.7947 valid_loss=0.3823 valid_acc=0.8027
epoch: 2 train_loss=0.3429 train_acc=0.8207 valid_loss=0.3545 valid_acc=0.8181
epoch: 3 train_loss=0.3215 train_acc=0.8340 valid_loss=0.3503 valid_acc=0.8210
epoch: 4 train_loss=0.3089 train_acc=0.8407 valid_loss=0.3476 valid_acc=0.8283
epoch: 5 train_loss=0.3006 train_acc=0.8462 valid_loss=0.3346 valid_acc=0.8246
epoch: 6 train_loss=0.2891 train_acc=0.8544 valid_loss=0.3407 valid_acc=0.8169
epoch: 7 train_loss=0.2844 train_acc=0.8578 valid_loss=0.3416 valid_acc=0.8193
epoch: 8 train_loss=0.2760 train_acc=0.8624 valid_loss=0.3383 valid_acc=0.8197
epoch: 9 train_loss=0.2697 train_acc=0.8633 valid_loss=0.3499 valid_acc=0.8136
epoch: 10 train_loss=0.2639 train_acc=0.8686 valid_loss=0.3539 valid_acc=0.8140
epoch: 11 train_loss=0.2550 train_acc=0.8734 valid_loss=0.3484 valid_acc=0.8238
epoch: 12 train_loss=0.2486 train_acc=0.8764 valid_loss=0.3729 valid_acc=0.8084
epoch: 13 train_loss=0.2465 train_acc=0.8774 valid_loss=0.3575 valid_acc=0.8124
epoch: 14 train_loss=0.2352 train_acc=0.8847 valid_loss=0.3505 valid_acc=0.8201
epoch: 15 train_loss=0.2365 train_acc=0.8825 valid_loss=0.3892 valid_acc=0.8088
epoch: 16 train_loss=0.2203 train_acc=0.8926 valid_loss=0.3637 valid_acc=0.8258
epoch: 17 train_loss=0.2153 train_acc=0.8964 valid_loss=0.3819 valid_acc=0.8140
epoch: 18 train_loss=0.2087 train_acc=0.8992 valid_loss=0.3800 valid_acc=0.8262
epoch: 19 train_loss=0.1990 train_acc=0.9049 valid_loss=0.3888 valid_acc=0.8181
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=20 loss=0.34176 accuracy=0.8425 Pre=0.7758 Rec=0.8703 F-score=0.8204 Pre_macro=0.8380 Rec_macro=0.8466 F-score_macro=0.8401
start_local_time: 2023-06-09-21-48 run over time: 2023-06-09-22-53 ---------------this program run over----------------
learning rate=0.00018 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=3
epoch: 0 train_loss=0.5180 train_acc=0.6546 valid_loss=0.4419 valid_acc=0.7503
epoch: 1 train_loss=0.3939 train_acc=0.7825 valid_loss=0.3808 valid_acc=0.8043
epoch: 2 train_loss=0.3358 train_acc=0.8250 valid_loss=0.3707 valid_acc=0.8023
epoch: 3 train_loss=0.2621 train_acc=0.8694 valid_loss=0.3876 valid_acc=0.8035
epoch: 4 train_loss=0.1897 train_acc=0.9113 valid_loss=0.4576 valid_acc=0.8059
epoch: 5 train_loss=0.1636 train_acc=0.9235 valid_loss=1.0305 valid_acc=0.6845
epoch: 6 train_loss=0.1293 train_acc=0.9411 valid_loss=1.3974 valid_acc=0.6265
epoch: 7 train_loss=0.1455 train_acc=0.9380 valid_loss=0.7154 valid_acc=0.7950
epoch: 8 train_loss=0.0468 train_acc=0.9812 valid_loss=1.1583 valid_acc=0.7739
epoch: 9 train_loss=0.0178 train_acc=0.9932 valid_loss=1.9554 valid_acc=0.7121
epoch: 10 train_loss=0.0165 train_acc=0.9940 valid_loss=1.6528 valid_acc=0.7373
epoch: 11 train_loss=0.0182 train_acc=0.9929 valid_loss=1.4926 valid_acc=0.7698
epoch: 12 train_loss=0.0184 train_acc=0.9925 valid_loss=1.9442 valid_acc=0.7479
epoch: 13 train_loss=0.0337 train_acc=0.9860 valid_loss=1.6127 valid_acc=0.7280
epoch: 14 train_loss=0.0413 train_acc=0.9817 valid_loss=1.9912 valid_acc=0.6971
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=15 loss=1.77489 accuracy=0.7114 Pre=0.9205 Rec=0.3301 F-score=0.4859 Pre_macro=0.7978 Rec_macro=0.6550 F-score_macro=0.6427
start_local_time: 2023-06-09-23-28 run over time: 2023-06-10-00-12 ---------------this program run over----------------
learning rate=0.00018 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=3
epoch: 0 train_loss=0.5228 train_acc=0.6412 valid_loss=0.4365 valid_acc=0.7527
epoch: 1 train_loss=0.3830 train_acc=0.7891 valid_loss=0.3934 valid_acc=0.7799
epoch: 2 train_loss=0.3203 train_acc=0.8313 valid_loss=0.3582 valid_acc=0.8181
epoch: 3 train_loss=0.2436 train_acc=0.8794 valid_loss=0.6791 valid_acc=0.7333
epoch: 4 train_loss=0.1954 train_acc=0.9088 valid_loss=1.0835 valid_acc=0.6732
epoch: 5 train_loss=0.1375 train_acc=0.9356 valid_loss=0.7412 valid_acc=0.7503
epoch: 6 train_loss=0.1022 train_acc=0.9563 valid_loss=0.6802 valid_acc=0.7832
epoch: 7 train_loss=0.1185 train_acc=0.9489 valid_loss=0.6741 valid_acc=0.7678
epoch: 8 train_loss=0.0226 train_acc=0.9927 valid_loss=1.0016 valid_acc=0.7775
epoch: 9 train_loss=0.0054 train_acc=0.9989 valid_loss=1.1441 valid_acc=0.7942
epoch: 10 train_loss=0.0018 train_acc=0.9996 valid_loss=1.2376 valid_acc=0.7868
epoch: 11 train_loss=0.0007 train_acc=0.9997 valid_loss=1.3365 valid_acc=0.7803
epoch: 12 train_loss=0.0004 train_acc=0.9997 valid_loss=1.4749 valid_acc=0.7718
epoch: 13 train_loss=0.0003 train_acc=0.9998 valid_loss=1.5685 valid_acc=0.7645
epoch: 14 train_loss=0.0002 train_acc=0.9998 valid_loss=1.6351 valid_acc=0.7617
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=15 loss=1.59607 accuracy=0.7833 Pre=0.8528 Rec=0.5747 F-score=0.6866 Pre_macro=0.8046 Rec_macro=0.7524 F-score_macro=0.7605
start_local_time: 2023-06-10-00-13 run over time: 2023-06-10-00-55 ---------------this program run over----------------
learning rate=0.00018 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=3
epoch: 0 train_loss=0.5200 train_acc=0.6447 valid_loss=0.4441 valid_acc=0.7471
epoch: 1 train_loss=0.3883 train_acc=0.7885 valid_loss=0.4151 valid_acc=0.7653
epoch: 2 train_loss=0.3456 train_acc=0.8162 valid_loss=0.3695 valid_acc=0.8071
epoch: 3 train_loss=0.3236 train_acc=0.8324 valid_loss=0.3811 valid_acc=0.7962
epoch: 4 train_loss=0.3099 train_acc=0.8394 valid_loss=0.4112 valid_acc=0.7710
epoch: 5 train_loss=0.3061 train_acc=0.8421 valid_loss=0.3560 valid_acc=0.8112
epoch: 6 train_loss=0.2923 train_acc=0.8523 valid_loss=0.3393 valid_acc=0.8189
epoch: 7 train_loss=0.2887 train_acc=0.8522 valid_loss=0.3425 valid_acc=0.8169
epoch: 8 train_loss=0.2797 train_acc=0.8595 valid_loss=0.3523 valid_acc=0.8189
epoch: 9 train_loss=0.2712 train_acc=0.8624 valid_loss=0.3654 valid_acc=0.8011
epoch: 10 train_loss=0.2671 train_acc=0.8632 valid_loss=0.3686 valid_acc=0.8055
epoch: 11 train_loss=0.2606 train_acc=0.8682 valid_loss=0.3609 valid_acc=0.8149
epoch: 12 train_loss=0.2574 train_acc=0.8709 valid_loss=0.3531 valid_acc=0.8149
epoch: 13 train_loss=0.2500 train_acc=0.8748 valid_loss=0.3643 valid_acc=0.8128
epoch: 14 train_loss=0.2436 train_acc=0.8797 valid_loss=0.3743 valid_acc=0.8039
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=15 loss=0.32911 accuracy=0.8454 Pre=0.7706 Rec=0.8910 F-score=0.8264 Pre_macro=0.8422 Rec_macro=0.8521 F-score_macro=0.8435
start_local_time: 2023-06-10-01-20 run over time: 2023-06-10-02-02 ---------------this program run over----------------
learning rate=0.00015 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=3
epoch: 0 train_loss=0.5368 train_acc=0.6241 valid_loss=0.4565 valid_acc=0.7263
epoch: 1 train_loss=0.4032 train_acc=0.7739 valid_loss=0.3933 valid_acc=0.7921
epoch: 2 train_loss=0.3591 train_acc=0.8082 valid_loss=0.3650 valid_acc=0.8136
epoch: 3 train_loss=0.3353 train_acc=0.8254 valid_loss=0.3569 valid_acc=0.8104
epoch: 4 train_loss=0.3185 train_acc=0.8351 valid_loss=0.3453 valid_acc=0.8165
epoch: 5 train_loss=0.3074 train_acc=0.8418 valid_loss=0.3406 valid_acc=0.8222
epoch: 6 train_loss=0.2992 train_acc=0.8468 valid_loss=0.3391 valid_acc=0.8214
epoch: 7 train_loss=0.2910 train_acc=0.8511 valid_loss=0.3485 valid_acc=0.8149
epoch: 8 train_loss=0.2840 train_acc=0.8559 valid_loss=0.3418 valid_acc=0.8254
epoch: 9 train_loss=0.2783 train_acc=0.8593 valid_loss=0.3436 valid_acc=0.8218
epoch: 10 train_loss=0.2737 train_acc=0.8629 valid_loss=0.3594 valid_acc=0.8246
epoch: 11 train_loss=0.2704 train_acc=0.8638 valid_loss=0.3420 valid_acc=0.8185
epoch: 12 train_loss=0.2629 train_acc=0.8684 valid_loss=0.3501 valid_acc=0.8136
epoch: 13 train_loss=0.2565 train_acc=0.8722 valid_loss=0.3400 valid_acc=0.8246
epoch: 14 train_loss=0.2511 train_acc=0.8756 valid_loss=0.3505 valid_acc=0.8262
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=15 loss=0.29591 accuracy=0.8486 Pre=0.8196 Rec=0.8124 F-score=0.8160 Pre_macro=0.8442 Rec_macro=0.8433 F-score_macro=0.8437
start_local_time: 2023-06-10-02-03 run over time: 2023-06-10-02-45 ---------------this program run over----------------
learning rate=0.00015 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=4
epoch: 0 train_loss=0.5325 train_acc=0.6387 valid_loss=0.4606 valid_acc=0.7430
epoch: 1 train_loss=0.4021 train_acc=0.7754 valid_loss=0.3965 valid_acc=0.7868
epoch: 2 train_loss=0.3573 train_acc=0.8112 valid_loss=0.3697 valid_acc=0.8051
epoch: 3 train_loss=0.3329 train_acc=0.8244 valid_loss=0.3518 valid_acc=0.8226
epoch: 4 train_loss=0.3171 train_acc=0.8358 valid_loss=0.3545 valid_acc=0.8157
epoch: 5 train_loss=0.3069 train_acc=0.8438 valid_loss=0.3478 valid_acc=0.8230
epoch: 6 train_loss=0.2988 train_acc=0.8475 valid_loss=0.3410 valid_acc=0.8222
epoch: 7 train_loss=0.2897 train_acc=0.8549 valid_loss=0.3356 valid_acc=0.8165
epoch: 8 train_loss=0.2826 train_acc=0.8571 valid_loss=0.3411 valid_acc=0.8149
epoch: 9 train_loss=0.2778 train_acc=0.8603 valid_loss=0.3398 valid_acc=0.8161
epoch: 10 train_loss=0.2700 train_acc=0.8638 valid_loss=0.3438 valid_acc=0.8226
epoch: 11 train_loss=0.2635 train_acc=0.8676 valid_loss=0.3558 valid_acc=0.8234
epoch: 12 train_loss=0.2623 train_acc=0.8688 valid_loss=0.3517 valid_acc=0.8181
epoch: 13 train_loss=0.2556 train_acc=0.8727 valid_loss=0.3561 valid_acc=0.8132
epoch: 14 train_loss=0.2475 train_acc=0.8765 valid_loss=0.3561 valid_acc=0.8181
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=15 loss=0.30782 accuracy=0.8494 Pre=0.7960 Rec=0.8546 F-score=0.8243 Pre_macro=0.8440 Rec_macro=0.8502 F-score_macro=0.8463
start_local_time: 2023-06-10-03-11 run over time: 2023-06-10-03-53 ---------------this program run over----------------
learning rate=0.00015 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=4
epoch: 0 train_loss=0.5352 train_acc=0.6305 valid_loss=0.4578 valid_acc=0.7389
epoch: 1 train_loss=0.4041 train_acc=0.7742 valid_loss=0.4012 valid_acc=0.7803
epoch: 2 train_loss=0.3618 train_acc=0.8064 valid_loss=0.3700 valid_acc=0.8035
epoch: 3 train_loss=0.3355 train_acc=0.8240 valid_loss=0.3565 valid_acc=0.8210
epoch: 4 train_loss=0.3175 train_acc=0.8357 valid_loss=0.3444 valid_acc=0.8193
epoch: 5 train_loss=0.3105 train_acc=0.8379 valid_loss=0.3505 valid_acc=0.8181
epoch: 6 train_loss=0.2999 train_acc=0.8444 valid_loss=0.3413 valid_acc=0.8242
epoch: 7 train_loss=0.2939 train_acc=0.8488 valid_loss=0.3633 valid_acc=0.8189
epoch: 8 train_loss=0.2878 train_acc=0.8524 valid_loss=0.3359 valid_acc=0.8222
epoch: 9 train_loss=0.2822 train_acc=0.8554 valid_loss=0.3398 valid_acc=0.8205
epoch: 10 train_loss=0.2758 train_acc=0.8606 valid_loss=0.3407 valid_acc=0.8230
epoch: 11 train_loss=0.2712 train_acc=0.8614 valid_loss=0.3463 valid_acc=0.8201
epoch: 12 train_loss=0.2678 train_acc=0.8620 valid_loss=0.3477 valid_acc=0.8197
epoch: 13 train_loss=0.2602 train_acc=0.8687 valid_loss=0.3410 valid_acc=0.8287
epoch: 14 train_loss=0.2548 train_acc=0.8726 valid_loss=0.3545 valid_acc=0.8153
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=15 loss=0.30406 accuracy=0.8523 Pre=0.8039 Rec=0.8497 F-score=0.8262 Pre_macro=0.8468 Rec_macro=0.8519 F-score_macro=0.8489
start_local_time: 2023-06-10-04-10 run over time: 2023-06-10-04-52 ---------------this program run over----------------
learning rate=0.00025 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=4
epoch: 0 train_loss=0.5033 train_acc=0.6708 valid_loss=0.4283 valid_acc=0.7690
epoch: 1 train_loss=0.3801 train_acc=0.7954 valid_loss=0.3756 valid_acc=0.7966
epoch: 2 train_loss=0.3354 train_acc=0.8253 valid_loss=0.3504 valid_acc=0.8214
epoch: 3 train_loss=0.3204 train_acc=0.8343 valid_loss=0.3549 valid_acc=0.8210
epoch: 4 train_loss=0.3047 train_acc=0.8436 valid_loss=0.3422 valid_acc=0.8295
epoch: 5 train_loss=0.2969 train_acc=0.8464 valid_loss=0.3410 valid_acc=0.8181
epoch: 6 train_loss=0.2893 train_acc=0.8536 valid_loss=0.3302 valid_acc=0.8335
epoch: 7 train_loss=0.2805 train_acc=0.8584 valid_loss=0.3349 valid_acc=0.8291
epoch: 8 train_loss=0.2740 train_acc=0.8609 valid_loss=0.3314 valid_acc=0.8307
epoch: 9 train_loss=0.2686 train_acc=0.8651 valid_loss=0.3550 valid_acc=0.8339
epoch: 10 train_loss=0.2603 train_acc=0.8713 valid_loss=0.3369 valid_acc=0.8348
epoch: 11 train_loss=0.2527 train_acc=0.8741 valid_loss=0.3431 valid_acc=0.8279
epoch: 12 train_loss=0.2462 train_acc=0.8802 valid_loss=0.3492 valid_acc=0.8262
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=13 loss=0.31385 accuracy=0.8470 Pre=0.8049 Rec=0.8310 F-score=0.8178 Pre_macro=0.8416 Rec_macro=0.8446 F-score_macro=0.8430
start_local_time: 2023-06-10-06-21 run over time: 2023-06-10-06-59 ---------------this program run over----------------
learning rate=0.00025 | fc dropout=0.25 |  weight decay=1e-60 | Multi_Nums=4
epoch: 0 train_loss=0.5000 train_acc=0.6689 valid_loss=0.4239 valid_acc=0.7564
epoch: 1 train_loss=0.3767 train_acc=0.7965 valid_loss=0.3739 valid_acc=0.7986
epoch: 2 train_loss=0.3332 train_acc=0.8253 valid_loss=0.3633 valid_acc=0.8092
epoch: 3 train_loss=0.3168 train_acc=0.8356 valid_loss=0.3454 valid_acc=0.8226
epoch: 4 train_loss=0.3086 train_acc=0.8428 valid_loss=0.3435 valid_acc=0.8128
epoch: 5 train_loss=0.2946 train_acc=0.8493 valid_loss=0.3443 valid_acc=0.8185
epoch: 6 train_loss=0.2922 train_acc=0.8507 valid_loss=0.3513 valid_acc=0.8250
epoch: 7 train_loss=0.2804 train_acc=0.8587 valid_loss=0.3425 valid_acc=0.8218
epoch: 8 train_loss=0.2726 train_acc=0.8640 valid_loss=0.3409 valid_acc=0.8274
epoch: 9 train_loss=0.2650 train_acc=0.8681 valid_loss=0.3438 valid_acc=0.8246
epoch: 10 train_loss=0.2594 train_acc=0.8733 valid_loss=0.3596 valid_acc=0.8210
epoch: 11 train_loss=0.2527 train_acc=0.8742 valid_loss=0.3477 valid_acc=0.8140
epoch: 12 train_loss=0.2470 train_acc=0.8804 valid_loss=0.3539 valid_acc=0.8238
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=13 loss=0.29132 accuracy=0.8584 Pre=0.8189 Rec=0.8438 F-score=0.8312 Pre_macro=0.8533 Rec_macro=0.8562 F-score_macro=0.8546
start_local_time: 2023-06-10-09-12 run over time: 2023-06-10-09-49 ---------------this program run over----------------
learning rate=0.0001 | fc dropout=0.25 |  weight decay=1e-60 | Multi_Nums=4
epoch: 0 train_loss=0.5515 train_acc=0.6161 valid_loss=0.4669 valid_acc=0.7361
epoch: 1 train_loss=0.4264 train_acc=0.7566 valid_loss=0.4195 valid_acc=0.7718
epoch: 2 train_loss=0.3882 train_acc=0.7841 valid_loss=0.3955 valid_acc=0.7913
epoch: 3 train_loss=0.3627 train_acc=0.8057 valid_loss=0.3785 valid_acc=0.8019
epoch: 4 train_loss=0.3424 train_acc=0.8201 valid_loss=0.3677 valid_acc=0.8027
epoch: 5 train_loss=0.3266 train_acc=0.8292 valid_loss=0.3610 valid_acc=0.8096
epoch: 6 train_loss=0.3145 train_acc=0.8363 valid_loss=0.3593 valid_acc=0.8112
epoch: 7 train_loss=0.3051 train_acc=0.8426 valid_loss=0.3592 valid_acc=0.8092
epoch: 8 train_loss=0.2974 train_acc=0.8467 valid_loss=0.3618 valid_acc=0.8067
epoch: 9 train_loss=0.2904 train_acc=0.8503 valid_loss=0.3587 valid_acc=0.8104
epoch: 10 train_loss=0.2854 train_acc=0.8536 valid_loss=0.3636 valid_acc=0.8100
epoch: 11 train_loss=0.2798 train_acc=0.8570 valid_loss=0.3628 valid_acc=0.8116
epoch: 12 train_loss=0.2741 train_acc=0.8599 valid_loss=0.3664 valid_acc=0.8112
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=13 loss=0.31564 accuracy=0.8474 Pre=0.7811 Rec=0.8762 F-score=0.8259 Pre_macro=0.8429 Rec_macro=0.8517 F-score_macro=0.8450
start_local_time: 2023-06-10-09-54 run over time: 2023-06-10-10-32 ---------------this program run over----------------
learning rate=0.0001 | fc dropout=0.25 |  weight decay=1e-60 | Multi_Nums=4
epoch: 0 train_loss=0.5553 train_acc=0.6115 valid_loss=0.4698 valid_acc=0.7292
epoch: 1 train_loss=0.4267 train_acc=0.7573 valid_loss=0.4202 valid_acc=0.7734
epoch: 2 train_loss=0.3851 train_acc=0.7863 valid_loss=0.3929 valid_acc=0.7950
epoch: 3 train_loss=0.3612 train_acc=0.8074 valid_loss=0.3781 valid_acc=0.8035
epoch: 4 train_loss=0.3410 train_acc=0.8223 valid_loss=0.3632 valid_acc=0.8096
epoch: 5 train_loss=0.3258 train_acc=0.8313 valid_loss=0.3558 valid_acc=0.8140
epoch: 6 train_loss=0.3134 train_acc=0.8380 valid_loss=0.3507 valid_acc=0.8136
epoch: 7 train_loss=0.3033 train_acc=0.8451 valid_loss=0.3473 valid_acc=0.8173
epoch: 8 train_loss=0.2950 train_acc=0.8483 valid_loss=0.3470 valid_acc=0.8153
epoch: 9 train_loss=0.2888 train_acc=0.8541 valid_loss=0.3450 valid_acc=0.8145
epoch: 10 train_loss=0.2822 train_acc=0.8573 valid_loss=0.3433 valid_acc=0.8177
epoch: 11 train_loss=0.2762 train_acc=0.8619 valid_loss=0.3514 valid_acc=0.8128
epoch: 12 train_loss=0.2698 train_acc=0.8664 valid_loss=0.3510 valid_acc=0.8161
epoch: 13 train_loss=0.2639 train_acc=0.8687 valid_loss=0.3532 valid_acc=0.8145
epoch: 14 train_loss=0.2585 train_acc=0.8726 valid_loss=0.3597 valid_acc=0.8181
epoch: 15 train_loss=0.2537 train_acc=0.8754 valid_loss=0.3601 valid_acc=0.8193
epoch: 16 train_loss=0.2475 train_acc=0.8800 valid_loss=0.3593 valid_acc=0.8214
epoch: 17 train_loss=0.2413 train_acc=0.8831 valid_loss=0.3687 valid_acc=0.8165
epoch: 18 train_loss=0.2359 train_acc=0.8849 valid_loss=0.3733 valid_acc=0.8177
epoch: 19 train_loss=0.2306 train_acc=0.8880 valid_loss=0.3746 valid_acc=0.8173
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=20 loss=0.32552 accuracy=0.8409 Pre=0.8033 Rec=0.8143 F-score=0.8088 Pre_macro=0.8357 Rec_macro=0.8370 F-score_macro=0.8363
start_local_time: 2023-06-10-10-35 run over time: 2023-06-10-11-40 ---------------this program run over----------------
learning rate=0.00012 | fc dropout=0.25 |  weight decay=1e-60 | Multi_Nums=4
epoch: 0 train_loss=0.5408 train_acc=0.6320 valid_loss=0.4623 valid_acc=0.7418
epoch: 1 train_loss=0.4204 train_acc=0.7619 valid_loss=0.4078 valid_acc=0.7812
epoch: 2 train_loss=0.3737 train_acc=0.7975 valid_loss=0.3837 valid_acc=0.7974
epoch: 3 train_loss=0.3462 train_acc=0.8184 valid_loss=0.3629 valid_acc=0.8116
epoch: 4 train_loss=0.3269 train_acc=0.8280 valid_loss=0.3562 valid_acc=0.8161
epoch: 5 train_loss=0.3134 train_acc=0.8376 valid_loss=0.3519 valid_acc=0.8149
epoch: 6 train_loss=0.3034 train_acc=0.8453 valid_loss=0.3453 valid_acc=0.8185
epoch: 7 train_loss=0.2947 train_acc=0.8499 valid_loss=0.3494 valid_acc=0.8169
epoch: 8 train_loss=0.2876 train_acc=0.8559 valid_loss=0.3502 valid_acc=0.8149
epoch: 9 train_loss=0.2802 train_acc=0.8587 valid_loss=0.3514 valid_acc=0.8173
epoch: 10 train_loss=0.2738 train_acc=0.8625 valid_loss=0.3586 valid_acc=0.8161
epoch: 11 train_loss=0.2677 train_acc=0.8655 valid_loss=0.3628 valid_acc=0.8136
epoch: 12 train_loss=0.2618 train_acc=0.8689 valid_loss=0.3692 valid_acc=0.8096
epoch: 13 train_loss=0.2565 train_acc=0.8720 valid_loss=0.3736 valid_acc=0.8100
epoch: 14 train_loss=0.2516 train_acc=0.8755 valid_loss=0.3774 valid_acc=0.8088
epoch: 15 train_loss=0.2478 train_acc=0.8787 valid_loss=0.3872 valid_acc=0.8104
epoch: 16 train_loss=0.2430 train_acc=0.8815 valid_loss=0.4012 valid_acc=0.8104
epoch: 17 train_loss=0.2407 train_acc=0.8816 valid_loss=0.4088 valid_acc=0.8067
epoch: 18 train_loss=0.2393 train_acc=0.8833 valid_loss=0.3877 valid_acc=0.8132
epoch: 19 train_loss=0.2373 train_acc=0.8838 valid_loss=0.3781 valid_acc=0.8193
epoch: 20 train_loss=0.2335 train_acc=0.8862 valid_loss=0.3767 valid_acc=0.8165
epoch: 21 train_loss=0.2265 train_acc=0.8881 valid_loss=0.3883 valid_acc=0.8153
epoch: 22 train_loss=0.2165 train_acc=0.8957 valid_loss=0.3914 valid_acc=0.8185
epoch: 23 train_loss=0.2131 train_acc=0.8965 valid_loss=0.4056 valid_acc=0.8080
epoch: 24 train_loss=0.2079 train_acc=0.9003 valid_loss=0.4083 valid_acc=0.8136
epoch: 25 train_loss=0.2043 train_acc=0.9022 valid_loss=0.4195 valid_acc=0.8084
epoch: 26 train_loss=0.2046 train_acc=0.9002 valid_loss=0.4244 valid_acc=0.8096
learning rate=0.00012 | fc dropout=0.25 |  weight decay=1e-60 | Multi_Nums=4
epoch: 0 train_loss=0.5508 train_acc=0.6066 valid_loss=0.4659 valid_acc=0.7288
epoch: 1 train_loss=0.4143 train_acc=0.7652 valid_loss=0.4011 valid_acc=0.7881
epoch: 2 train_loss=0.3691 train_acc=0.8000 valid_loss=0.3766 valid_acc=0.8039
epoch: 3 train_loss=0.3415 train_acc=0.8202 valid_loss=0.3582 valid_acc=0.8177
epoch: 4 train_loss=0.3223 train_acc=0.8323 valid_loss=0.3506 valid_acc=0.8210
epoch: 5 train_loss=0.3104 train_acc=0.8381 valid_loss=0.3462 valid_acc=0.8214
epoch: 6 train_loss=0.3008 train_acc=0.8445 valid_loss=0.3440 valid_acc=0.8205
epoch: 7 train_loss=0.2939 train_acc=0.8484 valid_loss=0.3461 valid_acc=0.8205
epoch: 8 train_loss=0.2873 train_acc=0.8523 valid_loss=0.3449 valid_acc=0.8185
epoch: 9 train_loss=0.2813 train_acc=0.8570 valid_loss=0.3444 valid_acc=0.8210
epoch: 10 train_loss=0.2765 train_acc=0.8602 valid_loss=0.3460 valid_acc=0.8205
epoch: 11 train_loss=0.2706 train_acc=0.8624 valid_loss=0.3505 valid_acc=0.8201
epoch: 12 train_loss=0.2646 train_acc=0.8662 valid_loss=0.3523 valid_acc=0.8210
epoch: 13 train_loss=0.2595 train_acc=0.8689 valid_loss=0.3525 valid_acc=0.8210
epoch: 14 train_loss=0.2548 train_acc=0.8723 valid_loss=0.3525 valid_acc=0.8185
epoch: 15 train_loss=0.2496 train_acc=0.8756 valid_loss=0.3527 valid_acc=0.8165
epoch: 16 train_loss=0.2435 train_acc=0.8795 valid_loss=0.3561 valid_acc=0.8116
epoch: 17 train_loss=0.2384 train_acc=0.8815 valid_loss=0.3649 valid_acc=0.8124
epoch: 18 train_loss=0.2326 train_acc=0.8852 valid_loss=0.3695 valid_acc=0.8132
epoch: 19 train_loss=0.2280 train_acc=0.8877 valid_loss=0.3758 valid_acc=0.8047
epoch: 20 train_loss=0.2225 train_acc=0.8917 valid_loss=0.3849 valid_acc=0.8043
epoch: 21 train_loss=0.2162 train_acc=0.8961 valid_loss=0.3955 valid_acc=0.8035
epoch: 22 train_loss=0.2125 train_acc=0.8976 valid_loss=0.4080 valid_acc=0.7966
epoch: 23 train_loss=0.2057 train_acc=0.9018 valid_loss=0.4202 valid_acc=0.7982
epoch: 24 train_loss=0.1994 train_acc=0.9064 valid_loss=0.4372 valid_acc=0.7946
epoch: 25 train_loss=0.1967 train_acc=0.9073 valid_loss=0.4358 valid_acc=0.7970
epoch: 26 train_loss=0.1960 train_acc=0.9082 valid_loss=0.4475 valid_acc=0.7893
epoch: 27 train_loss=0.2048 train_acc=0.9006 valid_loss=0.4215 valid_acc=0.8015
epoch: 28 train_loss=0.2133 train_acc=0.8944 valid_loss=0.4365 valid_acc=0.8031
epoch: 29 train_loss=0.2032 train_acc=0.8983 valid_loss=0.4413 valid_acc=0.8027
epoch: 30 train_loss=0.1860 train_acc=0.9097 valid_loss=0.4663 valid_acc=0.7982
epoch: 31 train_loss=0.1776 train_acc=0.9162 valid_loss=0.4781 valid_acc=0.8027
epoch: 32 train_loss=0.1696 train_acc=0.9192 valid_loss=0.4854 valid_acc=0.8096
epoch: 33 train_loss=0.1608 train_acc=0.9250 valid_loss=0.4950 valid_acc=0.8092
epoch: 34 train_loss=0.1542 train_acc=0.9302 valid_loss=0.5331 valid_acc=0.8059
learning rate=0.0008 | fc dropout=0.25 |  weight decay=1e-60 | Multi_Nums=4
epoch: 0 train_loss=0.5738 train_acc=0.5411 valid_loss=0.5257 valid_acc=0.7024
epoch: 1 train_loss=0.4827 train_acc=0.6848 valid_loss=0.4498 valid_acc=0.7365
epoch: 2 train_loss=0.4301 train_acc=0.7252 valid_loss=0.4140 valid_acc=0.7734
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=3 loss=0.40215 accuracy=0.7950 Pre=0.7834 Rec=0.6965 F-score=0.7374 Pre_macro=0.7926 Rec_macro=0.7805 F-score_macro=0.7847
start_local_time: 2023-06-10-18-19 run over time: 2023-06-10-18-23 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=1
epoch: 0 train_loss=0.5167 train_acc=0.6601 valid_loss=0.4390 valid_acc=0.7556
epoch: 1 train_loss=0.3993 train_acc=0.7796 valid_loss=0.3981 valid_acc=0.7840
epoch: 2 train_loss=0.3506 train_acc=0.8156 valid_loss=0.3596 valid_acc=0.8112
epoch: 3 train_loss=0.3313 train_acc=0.8273 valid_loss=0.3500 valid_acc=0.8197
epoch: 4 train_loss=0.3186 train_acc=0.8346 valid_loss=0.3416 valid_acc=0.8266
epoch: 5 train_loss=0.3063 train_acc=0.8414 valid_loss=0.3417 valid_acc=0.8283
epoch: 6 train_loss=0.2993 train_acc=0.8464 valid_loss=0.3350 valid_acc=0.8287
epoch: 7 train_loss=0.2909 train_acc=0.8509 valid_loss=0.3341 valid_acc=0.8270
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=8 loss=0.28932 accuracy=0.8584 Pre=0.8147 Rec=0.8507 F-score=0.8323 Pre_macro=0.8531 Rec_macro=0.8572 F-score_macro=0.8549
start_local_time: 2023-06-13-16-50 run over time: 2023-06-13-17-03 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=6
epoch: 0 train_loss=0.5378 train_acc=0.6322 valid_loss=0.4587 valid_acc=0.7393
epoch: 1 train_loss=0.3982 train_acc=0.7777 valid_loss=0.3921 valid_acc=0.7881
epoch: 2 train_loss=0.3478 train_acc=0.8180 valid_loss=0.3613 valid_acc=0.8140
epoch: 3 train_loss=0.3256 train_acc=0.8308 valid_loss=0.3687 valid_acc=0.8181
epoch: 4 train_loss=0.3140 train_acc=0.8366 valid_loss=0.3515 valid_acc=0.8262
epoch: 5 train_loss=0.3090 train_acc=0.8382 valid_loss=0.3331 valid_acc=0.8270
epoch: 6 train_loss=0.3002 train_acc=0.8454 valid_loss=0.3662 valid_acc=0.8201
epoch: 7 train_loss=0.2933 train_acc=0.8490 valid_loss=0.3307 valid_acc=0.8274
epoch: 8 train_loss=0.2839 train_acc=0.8564 valid_loss=0.3333 valid_acc=0.8295
epoch: 9 train_loss=0.2813 train_acc=0.8563 valid_loss=0.3367 valid_acc=0.8295
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.28940 accuracy=0.8555 Pre=0.8448 Rec=0.7967 F-score=0.8200 Pre_macro=0.8536 Rec_macro=0.8468 F-score_macro=0.8497
start_local_time: 2023-06-13-17-08 run over time: 2023-06-13-17-24 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=6
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=4
epoch: 0 train_loss=0.5255 train_acc=0.6533 valid_loss=0.4459 valid_acc=0.7434
epoch: 1 train_loss=0.3924 train_acc=0.7849 valid_loss=0.3715 valid_acc=0.8043
epoch: 2 train_loss=0.3452 train_acc=0.8209 valid_loss=0.3620 valid_acc=0.8120
epoch: 3 train_loss=0.3228 train_acc=0.8342 valid_loss=0.3528 valid_acc=0.8161
epoch: 4 train_loss=0.3103 train_acc=0.8388 valid_loss=0.3369 valid_acc=0.8291
epoch: 5 train_loss=0.3030 train_acc=0.8422 valid_loss=0.3362 valid_acc=0.8283
epoch: 6 train_loss=0.2963 train_acc=0.8463 valid_loss=0.3287 valid_acc=0.8368
epoch: 7 train_loss=0.2876 train_acc=0.8531 valid_loss=0.3290 valid_acc=0.8291
epoch: 8 train_loss=0.2854 train_acc=0.8552 valid_loss=0.3254 valid_acc=0.8279
epoch: 9 train_loss=0.2808 train_acc=0.8574 valid_loss=0.3280 valid_acc=0.8323
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.29124 accuracy=0.8571 Pre=0.8011 Rec=0.8703 F-score=0.8343 Pre_macro=0.8519 Rec_macro=0.8591 F-score_macro=0.8544
start_local_time: 2023-06-13-17-48 run over time: 2023-06-13-18-04 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.5227 train_acc=0.6544 valid_loss=0.4488 valid_acc=0.7531
epoch: 1 train_loss=0.3875 train_acc=0.7932 valid_loss=0.3742 valid_acc=0.8051
epoch: 2 train_loss=0.3436 train_acc=0.8213 valid_loss=0.3588 valid_acc=0.8136
epoch: 3 train_loss=0.3234 train_acc=0.8301 valid_loss=0.3471 valid_acc=0.8242
epoch: 4 train_loss=0.3147 train_acc=0.8366 valid_loss=0.3410 valid_acc=0.8262
epoch: 5 train_loss=0.3049 train_acc=0.8419 valid_loss=0.3328 valid_acc=0.8291
epoch: 6 train_loss=0.2985 train_acc=0.8484 valid_loss=0.3310 valid_acc=0.8295
epoch: 7 train_loss=0.2920 train_acc=0.8512 valid_loss=0.3290 valid_acc=0.8319
epoch: 8 train_loss=0.2833 train_acc=0.8553 valid_loss=0.3284 valid_acc=0.8335
epoch: 9 train_loss=0.2827 train_acc=0.8562 valid_loss=0.3282 valid_acc=0.8287
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.28661 accuracy=0.8592 Pre=0.8150 Rec=0.8527 F-score=0.8334 Pre_macro=0.8539 Rec_macro=0.8582 F-score_macro=0.8557
start_local_time: 2023-06-13-18-10 run over time: 2023-06-13-18-26 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=3
epoch: 0 train_loss=0.5244 train_acc=0.6513 valid_loss=0.4587 valid_acc=0.7418
epoch: 1 train_loss=0.3962 train_acc=0.7824 valid_loss=0.3773 valid_acc=0.8015
epoch: 2 train_loss=0.3494 train_acc=0.8174 valid_loss=0.3602 valid_acc=0.8149
epoch: 3 train_loss=0.3280 train_acc=0.8301 valid_loss=0.3496 valid_acc=0.8145
epoch: 4 train_loss=0.3126 train_acc=0.8383 valid_loss=0.3407 valid_acc=0.8270
epoch: 5 train_loss=0.3052 train_acc=0.8420 valid_loss=0.3416 valid_acc=0.8189
epoch: 6 train_loss=0.2992 train_acc=0.8469 valid_loss=0.3406 valid_acc=0.8230
epoch: 7 train_loss=0.2917 train_acc=0.8518 valid_loss=0.3287 valid_acc=0.8270
epoch: 8 train_loss=0.2867 train_acc=0.8550 valid_loss=0.3371 valid_acc=0.8303
epoch: 9 train_loss=0.2793 train_acc=0.8588 valid_loss=0.3397 valid_acc=0.8295
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.28189 accuracy=0.8559 Pre=0.8561 Rec=0.7829 F-score=0.8179 Pre_macro=0.8560 Rec_macro=0.8451 F-score_macro=0.8493
start_local_time: 2023-06-13-18-27 run over time: 2023-06-13-18-43 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=3
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=3
epoch: 0 train_loss=0.5217 train_acc=0.6587 valid_loss=0.4487 valid_acc=0.7519
epoch: 1 train_loss=0.3916 train_acc=0.7860 valid_loss=0.3760 valid_acc=0.8011
epoch: 2 train_loss=0.3483 train_acc=0.8166 valid_loss=0.3550 valid_acc=0.8205
epoch: 3 train_loss=0.3254 train_acc=0.8314 valid_loss=0.3555 valid_acc=0.8084
epoch: 4 train_loss=0.3154 train_acc=0.8384 valid_loss=0.3613 valid_acc=0.8011
epoch: 5 train_loss=0.3086 train_acc=0.8409 valid_loss=0.3582 valid_acc=0.8047
epoch: 6 train_loss=0.2989 train_acc=0.8474 valid_loss=0.3311 valid_acc=0.8226
epoch: 7 train_loss=0.2897 train_acc=0.8516 valid_loss=0.3327 valid_acc=0.8258
epoch: 8 train_loss=0.2851 train_acc=0.8539 valid_loss=0.3363 valid_acc=0.8307
epoch: 9 train_loss=0.2818 train_acc=0.8576 valid_loss=0.3346 valid_acc=0.8262
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.29242 accuracy=0.8628 Pre=0.8052 Rec=0.8811 F-score=0.8415 Pre_macro=0.8578 Rec_macro=0.8655 F-score_macro=0.8603
start_local_time: 2023-06-13-19-06 run over time: 2023-06-13-19-21 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.5122 train_acc=0.6653 valid_loss=0.4257 valid_acc=0.7560
epoch: 1 train_loss=0.3875 train_acc=0.7863 valid_loss=0.4086 valid_acc=0.7767
epoch: 2 train_loss=0.3475 train_acc=0.8176 valid_loss=0.3594 valid_acc=0.8197
epoch: 3 train_loss=0.3250 train_acc=0.8309 valid_loss=0.3494 valid_acc=0.8226
epoch: 4 train_loss=0.3152 train_acc=0.8375 valid_loss=0.3406 valid_acc=0.8177
epoch: 5 train_loss=0.3034 train_acc=0.8450 valid_loss=0.3360 valid_acc=0.8250
epoch: 6 train_loss=0.2963 train_acc=0.8478 valid_loss=0.3655 valid_acc=0.8019
epoch: 7 train_loss=0.2888 train_acc=0.8534 valid_loss=0.3283 valid_acc=0.8368
epoch: 8 train_loss=0.2823 train_acc=0.8575 valid_loss=0.3250 valid_acc=0.8356
epoch: 9 train_loss=0.2774 train_acc=0.8607 valid_loss=0.3305 valid_acc=0.8343
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.28685 accuracy=0.8600 Pre=0.8451 Rec=0.8094 F-score=0.8269 Pre_macro=0.8574 Rec_macro=0.8525 F-score_macro=0.8547
start_local_time: 2023-06-13-19-37 run over time: 2023-06-13-19-52 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.4869 train_acc=0.6939 valid_loss=0.4030 valid_acc=0.7812
epoch: 1 train_loss=0.3601 train_acc=0.8079 valid_loss=0.3604 valid_acc=0.8185
epoch: 2 train_loss=0.3282 train_acc=0.8309 valid_loss=0.3439 valid_acc=0.8262
epoch: 3 train_loss=0.3129 train_acc=0.8397 valid_loss=0.3356 valid_acc=0.8283
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.4740 train_acc=0.7048 valid_loss=0.4147 valid_acc=0.7714
epoch: 1 train_loss=0.3550 train_acc=0.8141 valid_loss=0.3583 valid_acc=0.8165
epoch: 2 train_loss=0.3287 train_acc=0.8283 valid_loss=0.3647 valid_acc=0.8222
epoch: 3 train_loss=0.3123 train_acc=0.8377 valid_loss=0.3558 valid_acc=0.8128
epoch: 4 train_loss=0.3040 train_acc=0.8434 valid_loss=0.3558 valid_acc=0.8226
epoch: 5 train_loss=0.2961 train_acc=0.8477 valid_loss=0.3347 valid_acc=0.8295
epoch: 6 train_loss=0.2880 train_acc=0.8536 valid_loss=0.3563 valid_acc=0.8173
epoch: 7 train_loss=0.2816 train_acc=0.8578 valid_loss=0.3264 valid_acc=0.8348
epoch: 8 train_loss=0.2773 train_acc=0.8605 valid_loss=0.3341 valid_acc=0.8287
epoch: 9 train_loss=0.2699 train_acc=0.8650 valid_loss=0.3501 valid_acc=0.8140
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.31534 accuracy=0.8393 Pre=0.7533 Rec=0.9086 F-score=0.8237 Pre_macro=0.8390 Rec_macro=0.8496 F-score_macro=0.8380
start_local_time: 2023-06-13-20-25 run over time: 2023-06-13-20-45 ---------------this program run over----------------
learning rate=0.00015 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.4867 train_acc=0.6943 valid_loss=0.4157 valid_acc=0.7726
epoch: 1 train_loss=0.3684 train_acc=0.8013 valid_loss=0.3688 valid_acc=0.8136
epoch: 2 train_loss=0.3384 train_acc=0.8226 valid_loss=0.3573 valid_acc=0.8181
epoch: 3 train_loss=0.3182 train_acc=0.8349 valid_loss=0.3414 valid_acc=0.8201
epoch: 4 train_loss=0.3126 train_acc=0.8385 valid_loss=0.3424 valid_acc=0.8258
epoch: 5 train_loss=0.3012 train_acc=0.8456 valid_loss=0.3405 valid_acc=0.8274
epoch: 6 train_loss=0.2934 train_acc=0.8487 valid_loss=0.3267 valid_acc=0.8258
epoch: 7 train_loss=0.2864 train_acc=0.8538 valid_loss=0.3267 valid_acc=0.8441
epoch: 8 train_loss=0.2817 train_acc=0.8560 valid_loss=0.3339 valid_acc=0.8303
epoch: 9 train_loss=0.2764 train_acc=0.8606 valid_loss=0.3371 valid_acc=0.8335
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.29163 accuracy=0.8608 Pre=0.8594 Rec=0.7927 F-score=0.8247 Pre_macro=0.8605 Rec_macro=0.8507 F-score_macro=0.8546
start_local_time: 2023-06-13-20-51 run over time: 2023-06-13-21-11 ---------------this program run over----------------
learning rate=0.00015 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.4889 train_acc=0.6916 valid_loss=0.4218 valid_acc=0.7730
epoch: 1 train_loss=0.3762 train_acc=0.7976 valid_loss=0.3627 valid_acc=0.8080
epoch: 2 train_loss=0.3375 train_acc=0.8232 valid_loss=0.3546 valid_acc=0.8145
epoch: 3 train_loss=0.3187 train_acc=0.8347 valid_loss=0.3383 valid_acc=0.8185
epoch: 4 train_loss=0.3071 train_acc=0.8421 valid_loss=0.3355 valid_acc=0.8262
epoch: 5 train_loss=0.3006 train_acc=0.8465 valid_loss=0.3393 valid_acc=0.8246
epoch: 6 train_loss=0.2903 train_acc=0.8512 valid_loss=0.3332 valid_acc=0.8323
epoch: 7 train_loss=0.2847 train_acc=0.8559 valid_loss=0.3204 valid_acc=0.8348
epoch: 8 train_loss=0.2770 train_acc=0.8598 valid_loss=0.3324 valid_acc=0.8270
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=9 loss=0.29021 accuracy=0.8624 Pre=0.8146 Rec=0.8635 F-score=0.8383 Pre_macro=0.8571 Rec_macro=0.8626 F-score_macro=0.8593
start_local_time: 2023-06-13-21-18 run over time: 2023-06-13-21-34 ---------------this program run over----------------
learning rate=0.00015 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.4904 train_acc=0.6875 valid_loss=0.4374 valid_acc=0.7596
learning rate=0.00015 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.4928 train_acc=0.6865 valid_loss=0.4222 valid_acc=0.7702
epoch: 1 train_loss=0.3705 train_acc=0.8009 valid_loss=0.3687 valid_acc=0.7982
epoch: 2 train_loss=0.3339 train_acc=0.8262 valid_loss=0.3548 valid_acc=0.8193
epoch: 3 train_loss=0.3182 train_acc=0.8357 valid_loss=0.3421 valid_acc=0.8210
epoch: 4 train_loss=0.3091 train_acc=0.8407 valid_loss=0.3346 valid_acc=0.8230
epoch: 5 train_loss=0.3006 train_acc=0.8475 valid_loss=0.3357 valid_acc=0.8299
epoch: 6 train_loss=0.2922 train_acc=0.8514 valid_loss=0.3319 valid_acc=0.8254
epoch: 7 train_loss=0.2865 train_acc=0.8533 valid_loss=0.3325 valid_acc=0.8299
epoch: 8 train_loss=0.2809 train_acc=0.8570 valid_loss=0.3358 valid_acc=0.8218
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=9 loss=0.30697 accuracy=0.8535 Pre=0.7844 Rec=0.8900 F-score=0.8339 Pre_macro=0.8494 Rec_macro=0.8589 F-score_macro=0.8514
start_local_time: 2023-06-13-21-42 run over time: 2023-06-13-21-58 ---------------this program run over----------------
learning rate=0.00015 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.4975 train_acc=0.6767 valid_loss=0.4177 valid_acc=0.7787
epoch: 1 train_loss=0.3644 train_acc=0.8042 valid_loss=0.3620 valid_acc=0.8031
epoch: 2 train_loss=0.3327 train_acc=0.8269 valid_loss=0.3416 valid_acc=0.8197
epoch: 3 train_loss=0.3159 train_acc=0.8354 valid_loss=0.3388 valid_acc=0.8205
epoch: 4 train_loss=0.3077 train_acc=0.8393 valid_loss=0.3375 valid_acc=0.8238
epoch: 5 train_loss=0.2971 train_acc=0.8464 valid_loss=0.3458 valid_acc=0.8258
epoch: 6 train_loss=0.2939 train_acc=0.8487 valid_loss=0.3444 valid_acc=0.8270
epoch: 7 train_loss=0.2865 train_acc=0.8544 valid_loss=0.3344 valid_acc=0.8145
epoch: 8 train_loss=0.2813 train_acc=0.8566 valid_loss=0.3274 valid_acc=0.8270
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=9 loss=0.29120 accuracy=0.8575 Pre=0.8137 Rec=0.8497 F-score=0.8313 Pre_macro=0.8523 Rec_macro=0.8564 F-score_macro=0.8540
start_local_time: 2023-06-13-23-03 run over time: 2023-06-13-23-20 ---------------this program run over----------------
learning rate=0.00015 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.5841 train_acc=0.5527 valid_loss=0.5550 valid_acc=0.5960
epoch: 1 train_loss=0.4822 train_acc=0.7050 valid_loss=0.4507 valid_acc=0.7548
epoch: 2 train_loss=0.4091 train_acc=0.7609 valid_loss=0.4027 valid_acc=0.7816
epoch: 3 train_loss=0.3733 train_acc=0.7877 valid_loss=0.3828 valid_acc=0.8006
epoch: 4 train_loss=0.3511 train_acc=0.8053 valid_loss=0.3701 valid_acc=0.8149
epoch: 5 train_loss=0.3333 train_acc=0.8160 valid_loss=0.3600 valid_acc=0.8201
epoch: 6 train_loss=0.3219 train_acc=0.8225 valid_loss=0.3493 valid_acc=0.8165
epoch: 7 train_loss=0.3142 train_acc=0.8249 valid_loss=0.3554 valid_acc=0.8132
epoch: 8 train_loss=0.3089 train_acc=0.8291 valid_loss=0.3390 valid_acc=0.8246
epoch: 9 train_loss=0.3007 train_acc=0.8320 valid_loss=0.3382 valid_acc=0.8250
learning rate=0.00015 | fc dropout=0.25 |  weight decay=1e-06 | Multi_Nums=2
epoch: 0 train_loss=0.5848 train_acc=0.5482 valid_loss=0.5590 valid_acc=0.6013
epoch: 1 train_loss=0.4860 train_acc=0.7016 valid_loss=0.4507 valid_acc=0.7495
epoch: 2 train_loss=0.4096 train_acc=0.7608 valid_loss=0.4095 valid_acc=0.7710
epoch: 3 train_loss=0.3738 train_acc=0.7873 valid_loss=0.3863 valid_acc=0.7982
epoch: 4 train_loss=0.3527 train_acc=0.8024 valid_loss=0.3665 valid_acc=0.8092
epoch: 5 train_loss=0.3340 train_acc=0.8145 valid_loss=0.3575 valid_acc=0.8153
epoch: 6 train_loss=0.3220 train_acc=0.8209 valid_loss=0.3524 valid_acc=0.8185
epoch: 7 train_loss=0.3163 train_acc=0.8239 valid_loss=0.3524 valid_acc=0.8222
epoch: 8 train_loss=0.3107 train_acc=0.8285 valid_loss=0.3414 valid_acc=0.8274
epoch: 9 train_loss=0.3020 train_acc=0.8309 valid_loss=0.3479 valid_acc=0.8210
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.30184 accuracy=0.8470 Pre=0.8443 Rec=0.7721 F-score=0.8066 Pre_macro=0.8465 Rec_macro=0.8359 F-score_macro=0.8400
start_local_time: 2023-06-13-23-21 run over time: 2023-06-13-23-48 ---------------this program run over----------------
learning rate=0.00015 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.4922 train_acc=0.6855 valid_loss=0.4103 valid_acc=0.7706
epoch: 1 train_loss=0.3702 train_acc=0.8018 valid_loss=0.3682 valid_acc=0.8092
epoch: 2 train_loss=0.3357 train_acc=0.8226 valid_loss=0.3465 valid_acc=0.8210
epoch: 3 train_loss=0.3204 train_acc=0.8341 valid_loss=0.3596 valid_acc=0.8104
epoch: 4 train_loss=0.3081 train_acc=0.8422 valid_loss=0.3526 valid_acc=0.8169
epoch: 5 train_loss=0.3024 train_acc=0.8456 valid_loss=0.3406 valid_acc=0.8230
epoch: 6 train_loss=0.2943 train_acc=0.8504 valid_loss=0.3360 valid_acc=0.8303
epoch: 7 train_loss=0.2864 train_acc=0.8560 valid_loss=0.3284 valid_acc=0.8279
epoch: 8 train_loss=0.2814 train_acc=0.8574 valid_loss=0.3331 valid_acc=0.8291
epoch: 9 train_loss=0.2771 train_acc=0.8598 valid_loss=0.3304 valid_acc=0.8283
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.28157 accuracy=0.8653 Pre=0.8330 Rec=0.8428 F-score=0.8379 Pre_macro=0.8607 Rec_macro=0.8619 F-score_macro=0.8613
start_local_time: 2023-06-13-23-55 run over time: 2023-06-14-00-12 ---------------this program run over----------------
learning rate=0.00015 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.4897 train_acc=0.6877 valid_loss=0.4267 valid_acc=0.7698
epoch: 1 train_loss=0.3741 train_acc=0.7989 valid_loss=0.3675 valid_acc=0.8116
epoch: 2 train_loss=0.3333 train_acc=0.8267 valid_loss=0.3505 valid_acc=0.8230
epoch: 3 train_loss=0.3183 train_acc=0.8340 valid_loss=0.3423 valid_acc=0.8266
epoch: 4 train_loss=0.3100 train_acc=0.8395 valid_loss=0.3410 valid_acc=0.8242
epoch: 5 train_loss=0.2994 train_acc=0.8448 valid_loss=0.3366 valid_acc=0.8274
epoch: 6 train_loss=0.2932 train_acc=0.8479 valid_loss=0.3351 valid_acc=0.8339
epoch: 7 train_loss=0.2922 train_acc=0.8508 valid_loss=0.3391 valid_acc=0.8250
epoch: 8 train_loss=0.2802 train_acc=0.8574 valid_loss=0.3328 valid_acc=0.8254
epoch: 9 train_loss=0.2770 train_acc=0.8607 valid_loss=0.3557 valid_acc=0.8149
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.31692 accuracy=0.8417 Pre=0.7612 Rec=0.8988 F-score=0.8243 Pre_macro=0.8398 Rec_macro=0.8502 F-score_macro=0.8402
start_local_time: 2023-06-14-00-15 run over time: 2023-06-14-00-32 ---------------this program run over----------------
learning rate=0.00018 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.4831 train_acc=0.6973 valid_loss=0.4199 valid_acc=0.7739
epoch: 1 train_loss=0.3688 train_acc=0.8017 valid_loss=0.3878 valid_acc=0.7994
epoch: 2 train_loss=0.3342 train_acc=0.8268 valid_loss=0.3565 valid_acc=0.8201
epoch: 3 train_loss=0.3162 train_acc=0.8379 valid_loss=0.3563 valid_acc=0.8254
epoch: 4 train_loss=0.3068 train_acc=0.8416 valid_loss=0.3439 valid_acc=0.8222
epoch: 5 train_loss=0.2960 train_acc=0.8484 valid_loss=0.3387 valid_acc=0.8274
epoch: 6 train_loss=0.2924 train_acc=0.8497 valid_loss=0.3425 valid_acc=0.8246
epoch: 7 train_loss=0.2825 train_acc=0.8550 valid_loss=0.3418 valid_acc=0.8238
epoch: 8 train_loss=0.2764 train_acc=0.8605 valid_loss=0.3231 valid_acc=0.8311
epoch: 9 train_loss=0.2694 train_acc=0.8645 valid_loss=0.3276 valid_acc=0.8291
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.27285 accuracy=0.8640 Pre=0.8432 Rec=0.8242 F-score=0.8336 Pre_macro=0.8607 Rec_macro=0.8581 F-score_macro=0.8593
start_local_time: 2023-06-14-00-33 run over time: 2023-06-14-00-49 ---------------this program run over----------------
learning rate=0.00018 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.00018 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.4853 train_acc=0.6942 valid_loss=0.4132 valid_acc=0.7734
epoch: 1 train_loss=0.3648 train_acc=0.8058 valid_loss=0.3685 valid_acc=0.8088
epoch: 2 train_loss=0.3283 train_acc=0.8322 valid_loss=0.3549 valid_acc=0.8177
epoch: 3 train_loss=0.3155 train_acc=0.8378 valid_loss=0.3414 valid_acc=0.8193
epoch: 4 train_loss=0.3031 train_acc=0.8439 valid_loss=0.3360 valid_acc=0.8238
epoch: 5 train_loss=0.2946 train_acc=0.8491 valid_loss=0.3511 valid_acc=0.8230
epoch: 6 train_loss=0.2872 train_acc=0.8536 valid_loss=0.3194 valid_acc=0.8295
epoch: 7 train_loss=0.2850 train_acc=0.8565 valid_loss=0.3408 valid_acc=0.8205
epoch: 8 train_loss=0.2771 train_acc=0.8584 valid_loss=0.3399 valid_acc=0.8311
epoch: 9 train_loss=0.2698 train_acc=0.8655 valid_loss=0.3258 valid_acc=0.8262
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.28968 accuracy=0.8547 Pre=0.7920 Rec=0.8792 F-score=0.8333 Pre_macro=0.8499 Rec_macro=0.8583 F-score_macro=0.8523
start_local_time: 2023-06-14-01-04 run over time: 2023-06-14-01-22 ---------------this program run over----------------
learning rate=0.00018 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.4768 train_acc=0.7021 valid_loss=0.3929 valid_acc=0.7860
epoch: 1 train_loss=0.3585 train_acc=0.8093 valid_loss=0.3710 valid_acc=0.8043
epoch: 2 train_loss=0.3273 train_acc=0.8301 valid_loss=0.3492 valid_acc=0.8193
epoch: 3 train_loss=0.3143 train_acc=0.8390 valid_loss=0.3369 valid_acc=0.8201
epoch: 4 train_loss=0.3037 train_acc=0.8446 valid_loss=0.3339 valid_acc=0.8254
epoch: 5 train_loss=0.2948 train_acc=0.8495 valid_loss=0.3301 valid_acc=0.8307
epoch: 6 train_loss=0.2889 train_acc=0.8526 valid_loss=0.3307 valid_acc=0.8283
epoch: 7 train_loss=0.2836 train_acc=0.8560 valid_loss=0.3216 valid_acc=0.8356
epoch: 8 train_loss=0.2755 train_acc=0.8613 valid_loss=0.3477 valid_acc=0.8132
epoch: 9 train_loss=0.2705 train_acc=0.8654 valid_loss=0.3224 valid_acc=0.8368
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.28560 accuracy=0.8640 Pre=0.8225 Rec=0.8556 F-score=0.8387 Pre_macro=0.8589 Rec_macro=0.8628 F-score_macro=0.8606
start_local_time: 2023-06-14-01-23 run over time: 2023-06-14-01-40 ---------------this program run over----------------
learning rate=0.00018 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=3
epoch: 0 train_loss=0.4784 train_acc=0.6987 valid_loss=0.3923 valid_acc=0.7885
epoch: 1 train_loss=0.3562 train_acc=0.8114 valid_loss=0.3558 valid_acc=0.8124
epoch: 2 train_loss=0.3253 train_acc=0.8308 valid_loss=0.3490 valid_acc=0.8201
epoch: 3 train_loss=0.3140 train_acc=0.8382 valid_loss=0.3423 valid_acc=0.8283
learning rate=0.00018 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=5
epoch: 0 train_loss=0.5306 train_acc=0.6379 valid_loss=0.4521 valid_acc=0.7438
epoch: 1 train_loss=0.3953 train_acc=0.7808 valid_loss=0.3778 valid_acc=0.7942
epoch: 2 train_loss=0.3485 train_acc=0.8179 valid_loss=0.3591 valid_acc=0.8153
epoch: 3 train_loss=0.3267 train_acc=0.8307 valid_loss=0.3474 valid_acc=0.8222
epoch: 4 train_loss=0.3203 train_acc=0.8337 valid_loss=0.3397 valid_acc=0.8242
epoch: 5 train_loss=0.3057 train_acc=0.8413 valid_loss=0.3438 valid_acc=0.8250
epoch: 6 train_loss=0.2995 train_acc=0.8450 valid_loss=0.3381 valid_acc=0.8295
epoch: 7 train_loss=0.2931 train_acc=0.8498 valid_loss=0.3367 valid_acc=0.8205
epoch: 8 train_loss=0.2858 train_acc=0.8540 valid_loss=0.3369 valid_acc=0.8165
epoch: 9 train_loss=0.2845 train_acc=0.8557 valid_loss=0.3320 valid_acc=0.8189
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.29673 accuracy=0.8559 Pre=0.7905 Rec=0.8861 F-score=0.8356 Pre_macro=0.8514 Rec_macro=0.8604 F-score_macro=0.8537
start_local_time: 2023-06-14-02-45 run over time: 2023-06-14-02-59 ---------------this program run over----------------
learning rate=0.00018 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=5
learning rate=0.00018 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=5
epoch: 0 train_loss=0.5756 train_acc=0.5762 valid_loss=0.5196 valid_acc=0.6825
epoch: 1 train_loss=0.4572 train_acc=0.7215 valid_loss=0.4317 valid_acc=0.7633
epoch: 2 train_loss=0.3904 train_acc=0.7764 valid_loss=0.3947 valid_acc=0.7897
epoch: 3 train_loss=0.3608 train_acc=0.7979 valid_loss=0.3718 valid_acc=0.8096
epoch: 4 train_loss=0.3398 train_acc=0.8100 valid_loss=0.3581 valid_acc=0.8149
epoch: 5 train_loss=0.3275 train_acc=0.8210 valid_loss=0.3592 valid_acc=0.8080
epoch: 6 train_loss=0.3197 train_acc=0.8230 valid_loss=0.3424 valid_acc=0.8230
epoch: 7 train_loss=0.3086 train_acc=0.8273 valid_loss=0.3447 valid_acc=0.8185
epoch: 8 train_loss=0.3043 train_acc=0.8313 valid_loss=0.3370 valid_acc=0.8238
epoch: 9 train_loss=0.2983 train_acc=0.8357 valid_loss=0.3327 valid_acc=0.8226
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.30005 accuracy=0.8502 Pre=0.7974 Rec=0.8546 F-score=0.8250 Pre_macro=0.8448 Rec_macro=0.8509 F-score_macro=0.8471
start_local_time: 2023-06-14-03-18 run over time: 2023-06-14-03-32 ---------------this program run over----------------
learning rate=0.00018 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=7
epoch: 0 train_loss=0.5805 train_acc=0.5591 valid_loss=0.5372 valid_acc=0.6894
epoch: 1 train_loss=0.4698 train_acc=0.7159 valid_loss=0.4406 valid_acc=0.7592
epoch: 2 train_loss=0.3971 train_acc=0.7693 valid_loss=0.3929 valid_acc=0.7921
epoch: 3 train_loss=0.3615 train_acc=0.7969 valid_loss=0.3677 valid_acc=0.7986
epoch: 4 train_loss=0.3366 train_acc=0.8135 valid_loss=0.3557 valid_acc=0.8153
epoch: 5 train_loss=0.3246 train_acc=0.8206 valid_loss=0.3500 valid_acc=0.8197
epoch: 6 train_loss=0.3140 train_acc=0.8259 valid_loss=0.3448 valid_acc=0.8149
epoch: 7 train_loss=0.3114 train_acc=0.8269 valid_loss=0.3407 valid_acc=0.8283
epoch: 8 train_loss=0.3048 train_acc=0.8338 valid_loss=0.3389 valid_acc=0.8287
epoch: 9 train_loss=0.2953 train_acc=0.8366 valid_loss=0.3454 valid_acc=0.8291
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.30183 accuracy=0.8433 Pre=0.8457 Rec=0.7593 F-score=0.8002 Pre_macro=0.8438 Rec_macro=0.8309 F-score_macro=0.8357
start_local_time: 2023-06-14-03-34 run over time: 2023-06-14-03-46 ---------------this program run over----------------
learning rate=0.00018 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=7
epoch: 0 train_loss=0.5222 train_acc=0.6506 valid_loss=0.4425 valid_acc=0.7633
epoch: 1 train_loss=0.3909 train_acc=0.7891 valid_loss=0.3734 valid_acc=0.8023
epoch: 2 train_loss=0.3457 train_acc=0.8185 valid_loss=0.3755 valid_acc=0.8063
epoch: 3 train_loss=0.3254 train_acc=0.8312 valid_loss=0.3589 valid_acc=0.8092
epoch: 4 train_loss=0.3136 train_acc=0.8384 valid_loss=0.3447 valid_acc=0.8254
epoch: 5 train_loss=0.3058 train_acc=0.8430 valid_loss=0.3510 valid_acc=0.8128
epoch: 6 train_loss=0.2975 train_acc=0.8457 valid_loss=0.3480 valid_acc=0.8238
epoch: 7 train_loss=0.2901 train_acc=0.8513 valid_loss=0.3548 valid_acc=0.8161
epoch: 8 train_loss=0.2820 train_acc=0.8582 valid_loss=0.3543 valid_acc=0.8112
epoch: 9 train_loss=0.2774 train_acc=0.8592 valid_loss=0.3398 valid_acc=0.8234
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.29431 accuracy=0.8547 Pre=0.7936 Rec=0.8762 F-score=0.8329 Pre_macro=0.8498 Rec_macro=0.8579 F-score_macro=0.8522
start_local_time: 2023-06-14-03-56 run over time: 2023-06-14-04-11 ---------------this program run over----------------
learning rate=0.00018 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=7
epoch: 0 train_loss=0.5352 train_acc=0.6333 valid_loss=0.4670 valid_acc=0.7397
epoch: 1 train_loss=0.3924 train_acc=0.7828 valid_loss=0.3791 valid_acc=0.7970
epoch: 2 train_loss=0.3443 train_acc=0.8190 valid_loss=0.3573 valid_acc=0.8132
epoch: 3 train_loss=0.3225 train_acc=0.8322 valid_loss=0.3448 valid_acc=0.8201
epoch: 4 train_loss=0.3136 train_acc=0.8369 valid_loss=0.3426 valid_acc=0.8262
epoch: 5 train_loss=0.3071 train_acc=0.8402 valid_loss=0.3342 valid_acc=0.8258
epoch: 6 train_loss=0.2957 train_acc=0.8480 valid_loss=0.3397 valid_acc=0.8291
epoch: 7 train_loss=0.2943 train_acc=0.8485 valid_loss=0.3333 valid_acc=0.8266
epoch: 8 train_loss=0.2847 train_acc=0.8530 valid_loss=0.3444 valid_acc=0.8335
epoch: 9 train_loss=0.2814 train_acc=0.8582 valid_loss=0.3292 valid_acc=0.8299
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.29686 accuracy=0.8523 Pre=0.7863 Rec=0.8821 F-score=0.8315 Pre_macro=0.8478 Rec_macro=0.8567 F-score_macro=0.8500
start_local_time: 2023-06-14-04-15 run over time: 2023-06-14-04-30 ---------------this program run over----------------
learning rate=0.00018 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=7
epoch: 0 train_loss=0.5371 train_acc=0.6305 valid_loss=0.4565 valid_acc=0.7418
epoch: 1 train_loss=0.4026 train_acc=0.7768 valid_loss=0.3842 valid_acc=0.7986
epoch: 2 train_loss=0.3503 train_acc=0.8128 valid_loss=0.3590 valid_acc=0.8136
epoch: 3 train_loss=0.3310 train_acc=0.8280 valid_loss=0.3519 valid_acc=0.8222
epoch: 4 train_loss=0.3179 train_acc=0.8352 valid_loss=0.3635 valid_acc=0.8185
epoch: 5 train_loss=0.3089 train_acc=0.8394 valid_loss=0.3454 valid_acc=0.8299
epoch: 6 train_loss=0.3017 train_acc=0.8447 valid_loss=0.3319 valid_acc=0.8266
epoch: 7 train_loss=0.2948 train_acc=0.8488 valid_loss=0.3284 valid_acc=0.8311
epoch: 8 train_loss=0.2882 train_acc=0.8509 valid_loss=0.3344 valid_acc=0.8258
epoch: 9 train_loss=0.2836 train_acc=0.8544 valid_loss=0.3331 valid_acc=0.8287
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.29438 accuracy=0.8498 Pre=0.7924 Rec=0.8625 F-score=0.8260 Pre_macro=0.8446 Rec_macro=0.8517 F-score_macro=0.8470
start_local_time: 2023-06-14-04-36 run over time: 2023-06-14-04-50 ---------------this program run over----------------
learning rate=0.00018 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=8
epoch: 0 train_loss=0.5245 train_acc=0.6521 valid_loss=0.4478 valid_acc=0.7625
epoch: 1 train_loss=0.4009 train_acc=0.7778 valid_loss=0.3895 valid_acc=0.7950
epoch: 2 train_loss=0.3569 train_acc=0.8125 valid_loss=0.3612 valid_acc=0.8116
epoch: 3 train_loss=0.3312 train_acc=0.8268 valid_loss=0.3505 valid_acc=0.8132
epoch: 4 train_loss=0.3166 train_acc=0.8364 valid_loss=0.3435 valid_acc=0.8238
epoch: 5 train_loss=0.3076 train_acc=0.8401 valid_loss=0.3375 valid_acc=0.8250
epoch: 6 train_loss=0.3017 train_acc=0.8446 valid_loss=0.3374 valid_acc=0.8307
epoch: 7 train_loss=0.2979 train_acc=0.8483 valid_loss=0.3304 valid_acc=0.8295
epoch: 8 train_loss=0.2867 train_acc=0.8540 valid_loss=0.3389 valid_acc=0.8274
epoch: 9 train_loss=0.2821 train_acc=0.8551 valid_loss=0.3363 valid_acc=0.8230
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.28769 accuracy=0.8588 Pre=0.8057 Rec=0.8674 F-score=0.8354 Pre_macro=0.8535 Rec_macro=0.8600 F-score_macro=0.8559
start_local_time: 2023-06-14-04-54 run over time: 2023-06-14-05-09 ---------------this program run over----------------
learning rate=0.00018 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=8
epoch: 0 train_loss=0.5224 train_acc=0.6526 valid_loss=0.4645 valid_acc=0.7507
epoch: 1 train_loss=0.3943 train_acc=0.7843 valid_loss=0.3825 valid_acc=0.8031
epoch: 2 train_loss=0.3488 train_acc=0.8176 valid_loss=0.3651 valid_acc=0.8084
epoch: 3 train_loss=0.3267 train_acc=0.8320 valid_loss=0.3550 valid_acc=0.8149
epoch: 4 train_loss=0.3138 train_acc=0.8367 valid_loss=0.3446 valid_acc=0.8295
epoch: 5 train_loss=0.3054 train_acc=0.8432 valid_loss=0.3295 valid_acc=0.8372
epoch: 6 train_loss=0.2963 train_acc=0.8500 valid_loss=0.3399 valid_acc=0.8335
epoch: 7 train_loss=0.2898 train_acc=0.8520 valid_loss=0.3342 valid_acc=0.8303
epoch: 8 train_loss=0.2823 train_acc=0.8570 valid_loss=0.3321 valid_acc=0.8352
learning rate=0.00018 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=8
epoch: 0 train_loss=0.4783 train_acc=0.6968 valid_loss=0.3942 valid_acc=0.7832
epoch: 1 train_loss=0.3556 train_acc=0.8113 valid_loss=0.3797 valid_acc=0.7998
epoch: 2 train_loss=0.3254 train_acc=0.8322 valid_loss=0.3533 valid_acc=0.8210
epoch: 3 train_loss=0.3128 train_acc=0.8375 valid_loss=0.3474 valid_acc=0.8214
epoch: 4 train_loss=0.3002 train_acc=0.8450 valid_loss=0.3315 valid_acc=0.8262
epoch: 5 train_loss=0.2947 train_acc=0.8490 valid_loss=0.3285 valid_acc=0.8327
epoch: 6 train_loss=0.2862 train_acc=0.8532 valid_loss=0.3408 valid_acc=0.8226
epoch: 7 train_loss=0.2797 train_acc=0.8579 valid_loss=0.3303 valid_acc=0.8266
epoch: 8 train_loss=0.2737 train_acc=0.8611 valid_loss=0.3312 valid_acc=0.8327
epoch: 9 train_loss=0.2651 train_acc=0.8676 valid_loss=0.3442 valid_acc=0.8287
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.28814 accuracy=0.8523 Pre=0.8200 Rec=0.8232 F-score=0.8216 Pre_macro=0.8476 Rec_macro=0.8480 F-score_macro=0.8478
start_local_time: 2023-06-14-05-27 run over time: 2023-06-14-05-43 ---------------this program run over----------------
learning rate=0.00018 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=8
learning rate=0.00018 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=8
learning rate=0.00018 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=8
learning rate=0.00018 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=8
learning rate=0.00018 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=8
learning rate=0.00018 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=8
learning rate=0.00018 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=8
learning rate=0.00025 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.00025 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.00025 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.4776 train_acc=0.7009 valid_loss=0.4050 valid_acc=0.7775
epoch: 1 train_loss=0.3540 train_acc=0.8139 valid_loss=0.3595 valid_acc=0.8149
epoch: 2 train_loss=0.3307 train_acc=0.8284 valid_loss=0.3648 valid_acc=0.8051
epoch: 3 train_loss=0.3147 train_acc=0.8376 valid_loss=0.3431 valid_acc=0.8218
epoch: 4 train_loss=0.3028 train_acc=0.8455 valid_loss=0.3351 valid_acc=0.8274
epoch: 5 train_loss=0.2936 train_acc=0.8506 valid_loss=0.3308 valid_acc=0.8279
epoch: 6 train_loss=0.2871 train_acc=0.8557 valid_loss=0.3383 valid_acc=0.8274
epoch: 7 train_loss=0.2800 train_acc=0.8579 valid_loss=0.3394 valid_acc=0.8246
epoch: 8 train_loss=0.2794 train_acc=0.8591 valid_loss=0.3283 valid_acc=0.8315
epoch: 9 train_loss=0.2679 train_acc=0.8650 valid_loss=0.3289 valid_acc=0.8327
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.28804 accuracy=0.8612 Pre=0.8159 Rec=0.8576 F-score=0.8362 Pre_macro=0.8559 Rec_macro=0.8607 F-score_macro=0.8579
start_local_time: 2023-06-14-20-21 run over time: 2023-06-14-20-38 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.4713 train_acc=0.7072 valid_loss=0.4220 valid_acc=0.7649
epoch: 1 train_loss=0.3543 train_acc=0.8113 valid_loss=0.3730 valid_acc=0.8059
epoch: 2 train_loss=0.3256 train_acc=0.8318 valid_loss=0.3504 valid_acc=0.8205
epoch: 3 train_loss=0.3139 train_acc=0.8382 valid_loss=0.3373 valid_acc=0.8262
epoch: 4 train_loss=0.3040 train_acc=0.8428 valid_loss=0.3494 valid_acc=0.8140
epoch: 5 train_loss=0.2903 train_acc=0.8524 valid_loss=0.3233 valid_acc=0.8360
epoch: 6 train_loss=0.2832 train_acc=0.8555 valid_loss=0.3279 valid_acc=0.8311
epoch: 7 train_loss=0.2768 train_acc=0.8624 valid_loss=0.3295 valid_acc=0.8262
epoch: 8 train_loss=0.2669 train_acc=0.8661 valid_loss=0.3334 valid_acc=0.8331
epoch: 9 train_loss=0.2610 train_acc=0.8699 valid_loss=0.3372 valid_acc=0.8283
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.30180 accuracy=0.8523 Pre=0.7848 Rec=0.8851 F-score=0.8319 Pre_macro=0.8480 Rec_macro=0.8571 F-score_macro=0.8501
start_local_time: 2023-06-14-20-45 run over time: 2023-06-14-21-02 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.4758 train_acc=0.7018 valid_loss=0.4280 valid_acc=0.7548
epoch: 1 train_loss=0.3538 train_acc=0.8134 valid_loss=0.3697 valid_acc=0.8088
epoch: 2 train_loss=0.3272 train_acc=0.8270 valid_loss=0.3459 valid_acc=0.8201
epoch: 3 train_loss=0.3138 train_acc=0.8375 valid_loss=0.3473 valid_acc=0.8254
epoch: 4 train_loss=0.3043 train_acc=0.8447 valid_loss=0.3330 valid_acc=0.8291
epoch: 5 train_loss=0.2941 train_acc=0.8495 valid_loss=0.3327 valid_acc=0.8287
epoch: 6 train_loss=0.2902 train_acc=0.8493 valid_loss=0.3329 valid_acc=0.8242
epoch: 7 train_loss=0.2802 train_acc=0.8570 valid_loss=0.3315 valid_acc=0.8319
epoch: 8 train_loss=0.2747 train_acc=0.8623 valid_loss=0.3287 valid_acc=0.8303
epoch: 9 train_loss=0.2691 train_acc=0.8654 valid_loss=0.3236 valid_acc=0.8343
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.28707 accuracy=0.8612 Pre=0.8485 Rec=0.8084 F-score=0.8280 Pre_macro=0.8590 Rec_macro=0.8534 F-score_macro=0.8558
start_local_time: 2023-06-14-21-05 run over time: 2023-06-14-21-22 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.4731 train_acc=0.7033 valid_loss=0.3865 valid_acc=0.7881
epoch: 1 train_loss=0.3549 train_acc=0.8128 valid_loss=0.3542 valid_acc=0.8169
epoch: 2 train_loss=0.3249 train_acc=0.8302 valid_loss=0.3441 valid_acc=0.8230
epoch: 3 train_loss=0.3135 train_acc=0.8384 valid_loss=0.3530 valid_acc=0.8153
epoch: 4 train_loss=0.3026 train_acc=0.8454 valid_loss=0.3403 valid_acc=0.8258
epoch: 5 train_loss=0.3013 train_acc=0.8436 valid_loss=0.3327 valid_acc=0.8262
epoch: 6 train_loss=0.2917 train_acc=0.8499 valid_loss=0.3455 valid_acc=0.8169
epoch: 7 train_loss=0.2824 train_acc=0.8567 valid_loss=0.3277 valid_acc=0.8258
epoch: 8 train_loss=0.2775 train_acc=0.8599 valid_loss=0.3290 valid_acc=0.8307
epoch: 9 train_loss=0.2717 train_acc=0.8621 valid_loss=0.3305 valid_acc=0.8331
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.27660 accuracy=0.8567 Pre=0.8342 Rec=0.8153 F-score=0.8246 Pre_macro=0.8531 Rec_macro=0.8506 F-score_macro=0.8518
start_local_time: 2023-06-14-21-39 run over time: 2023-06-14-21-56 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.3 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.4686 train_acc=0.7098 valid_loss=0.3819 valid_acc=0.7937
epoch: 1 train_loss=0.3505 train_acc=0.8140 valid_loss=0.3578 valid_acc=0.8161
epoch: 2 train_loss=0.3252 train_acc=0.8328 valid_loss=0.3458 valid_acc=0.8185
epoch: 3 train_loss=0.3093 train_acc=0.8383 valid_loss=0.3472 valid_acc=0.8291
epoch: 4 train_loss=0.3043 train_acc=0.8434 valid_loss=0.3434 valid_acc=0.8246
epoch: 5 train_loss=0.2930 train_acc=0.8491 valid_loss=0.3296 valid_acc=0.8299
epoch: 6 train_loss=0.2851 train_acc=0.8552 valid_loss=0.3311 valid_acc=0.8303
epoch: 7 train_loss=0.2790 train_acc=0.8587 valid_loss=0.3413 valid_acc=0.8266
epoch: 8 train_loss=0.2738 train_acc=0.8630 valid_loss=0.3411 valid_acc=0.8270
learning rate=0.0002 | fc dropout=0.4 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.4819 train_acc=0.6926 valid_loss=0.4112 valid_acc=0.7702
epoch: 1 train_loss=0.3607 train_acc=0.8095 valid_loss=0.3607 valid_acc=0.8108
epoch: 2 train_loss=0.3299 train_acc=0.8305 valid_loss=0.3515 valid_acc=0.8140
epoch: 3 train_loss=0.3140 train_acc=0.8387 valid_loss=0.3449 valid_acc=0.8193
epoch: 4 train_loss=0.3052 train_acc=0.8440 valid_loss=0.3401 valid_acc=0.8230
epoch: 5 train_loss=0.2955 train_acc=0.8493 valid_loss=0.3370 valid_acc=0.8230
epoch: 6 train_loss=0.2851 train_acc=0.8560 valid_loss=0.3361 valid_acc=0.8165
epoch: 7 train_loss=0.2773 train_acc=0.8607 valid_loss=0.3453 valid_acc=0.8246
epoch: 8 train_loss=0.2719 train_acc=0.8634 valid_loss=0.3436 valid_acc=0.8299
epoch: 9 train_loss=0.2670 train_acc=0.8677 valid_loss=0.3343 valid_acc=0.8262
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.29145 accuracy=0.8575 Pre=0.8155 Rec=0.8468 F-score=0.8308 Pre_macro=0.8523 Rec_macro=0.8560 F-score_macro=0.8539
start_local_time: 2023-06-15-01-33 run over time: 2023-06-15-01-49 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.18 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.4738 train_acc=0.7085 valid_loss=0.3953 valid_acc=0.7848
epoch: 1 train_loss=0.3590 train_acc=0.8106 valid_loss=0.3564 valid_acc=0.8124
epoch: 2 train_loss=0.3249 train_acc=0.8300 valid_loss=0.3545 valid_acc=0.8246
epoch: 3 train_loss=0.3121 train_acc=0.8390 valid_loss=0.3468 valid_acc=0.8108
epoch: 4 train_loss=0.3035 train_acc=0.8431 valid_loss=0.3421 valid_acc=0.8283
epoch: 5 train_loss=0.2950 train_acc=0.8517 valid_loss=0.3421 valid_acc=0.8214
epoch: 6 train_loss=0.2858 train_acc=0.8544 valid_loss=0.3632 valid_acc=0.8197
epoch: 7 train_loss=0.2769 train_acc=0.8610 valid_loss=0.3224 valid_acc=0.8238
epoch: 8 train_loss=0.2704 train_acc=0.8635 valid_loss=0.3273 valid_acc=0.8250
epoch: 9 train_loss=0.2649 train_acc=0.8678 valid_loss=0.3226 valid_acc=0.8311
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.28064 accuracy=0.8677 Pre=0.8327 Rec=0.8507 F-score=0.8416 Pre_macro=0.8630 Rec_macro=0.8652 F-score_macro=0.8640
start_local_time: 2023-06-15-02-16 run over time: 2023-06-15-02-33 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.18 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.4720 train_acc=0.7010 valid_loss=0.4064 valid_acc=0.7844
epoch: 1 train_loss=0.3526 train_acc=0.8120 valid_loss=0.3660 valid_acc=0.8153
epoch: 2 train_loss=0.3240 train_acc=0.8328 valid_loss=0.3377 valid_acc=0.8238
epoch: 3 train_loss=0.3119 train_acc=0.8395 valid_loss=0.3377 valid_acc=0.8250
epoch: 4 train_loss=0.3080 train_acc=0.8417 valid_loss=0.3997 valid_acc=0.7978
epoch: 5 train_loss=0.2973 train_acc=0.8482 valid_loss=0.3375 valid_acc=0.8287
epoch: 6 train_loss=0.2892 train_acc=0.8534 valid_loss=0.3240 valid_acc=0.8303
epoch: 7 train_loss=0.2817 train_acc=0.8577 valid_loss=0.3447 valid_acc=0.8214
epoch: 8 train_loss=0.2796 train_acc=0.8585 valid_loss=0.3430 valid_acc=0.8181
epoch: 9 train_loss=0.2721 train_acc=0.8625 valid_loss=0.3273 valid_acc=0.8323
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.28581 accuracy=0.8604 Pre=0.7988 Rec=0.8851 F-score=0.8397 Pre_macro=0.8556 Rec_macro=0.8640 F-score_macro=0.8580
start_local_time: 2023-06-15-02-35 run over time: 2023-06-15-02-52 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.18 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.47885 train_acc=0.69988 valid_loss=0.40226 valid_acc=0.77954
epoch: 1 train_loss=0.35763 train_acc=0.81367 valid_loss=0.35810 valid_acc=0.81405
epoch: 2 train_loss=0.32679 train_acc=0.82924 valid_loss=0.35399 valid_acc=0.81689
epoch: 3 train_loss=0.31098 train_acc=0.83908 valid_loss=0.34428 valid_acc=0.82460
epoch: 4 train_loss=0.30375 train_acc=0.84365 valid_loss=0.33478 valid_acc=0.82704
epoch: 5 train_loss=0.29790 train_acc=0.84639 valid_loss=0.32617 valid_acc=0.82785
epoch: 6 train_loss=0.29128 train_acc=0.85146 valid_loss=0.32538 valid_acc=0.82907
epoch: 7 train_loss=0.28020 train_acc=0.85765 valid_loss=0.35307 valid_acc=0.82988
epoch: 8 train_loss=0.27436 train_acc=0.86262 valid_loss=0.33944 valid_acc=0.82866
epoch: 9 train_loss=0.26884 train_acc=0.86511 valid_loss=0.32938 valid_acc=0.82663
epoch: 10 train_loss=0.26290 train_acc=0.86790 valid_loss=0.33005 valid_acc=0.82866
epoch: 11 train_loss=0.25666 train_acc=0.87277 valid_loss=0.33967 valid_acc=0.83069
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=12 loss=0.29080 accuracy=0.85552 Pre=0.85064 Rec=0.78880 F-score=0.81855 Pre_macro=0.85459 Rec_macro=0.84565 F-score_macro=0.84926
start_local_time: 2023-06-15-03-04 run over time: 2023-06-15-03-24 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.18 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.47847 train_acc=0.69546 valid_loss=0.40114 valid_acc=0.78279
epoch: 1 train_loss=0.35642 train_acc=0.80930 valid_loss=0.36570 valid_acc=0.81648
epoch: 2 train_loss=0.32502 train_acc=0.83147 valid_loss=0.34064 valid_acc=0.82420
epoch: 3 train_loss=0.31460 train_acc=0.83584 valid_loss=0.33851 valid_acc=0.82623
epoch: 4 train_loss=0.30440 train_acc=0.84573 valid_loss=0.33615 valid_acc=0.82623
epoch: 5 train_loss=0.29443 train_acc=0.84842 valid_loss=0.33000 valid_acc=0.82704
epoch: 6 train_loss=0.28678 train_acc=0.85440 valid_loss=0.33282 valid_acc=0.82988
epoch: 7 train_loss=0.28233 train_acc=0.85648 valid_loss=0.31762 valid_acc=0.83435
epoch: 8 train_loss=0.27557 train_acc=0.86074 valid_loss=0.33950 valid_acc=0.83394
epoch: 9 train_loss=0.26899 train_acc=0.86546 valid_loss=0.32808 valid_acc=0.83029
epoch: 10 train_loss=0.26176 train_acc=0.87094 valid_loss=0.32898 valid_acc=0.83151
epoch: 11 train_loss=0.25364 train_acc=0.87571 valid_loss=0.33350 valid_acc=0.83272
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=12 loss=0.28457 accuracy=0.85227 Pre=0.82766 Rec=0.81139 F-score=0.81944 Pre_macro=0.84834 Rec_macro=0.84622 F-score_macro=0.84722
start_local_time: 2023-06-15-03-28 run over time: 2023-06-15-03-49 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.18 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.46537 train_acc=0.71099 valid_loss=0.38951 valid_acc=0.79375
epoch: 1 train_loss=0.35133 train_acc=0.81478 valid_loss=0.35009 valid_acc=0.81202
epoch: 2 train_loss=0.32332 train_acc=0.83213 valid_loss=0.33929 valid_acc=0.82460
epoch: 3 train_loss=0.31186 train_acc=0.83923 valid_loss=0.33679 valid_acc=0.82136
epoch: 4 train_loss=0.30073 train_acc=0.84674 valid_loss=0.33796 valid_acc=0.82582
epoch: 5 train_loss=0.29371 train_acc=0.85050 valid_loss=0.32745 valid_acc=0.83232
epoch: 6 train_loss=0.28325 train_acc=0.85582 valid_loss=0.32804 valid_acc=0.82785
epoch: 7 train_loss=0.27877 train_acc=0.85988 valid_loss=0.32491 valid_acc=0.82948
epoch: 8 train_loss=0.27106 train_acc=0.86328 valid_loss=0.31080 valid_acc=0.83963
epoch: 9 train_loss=0.26669 train_acc=0.86841 valid_loss=0.32138 valid_acc=0.83516
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.28969 accuracy=0.85714 Pre=0.81297 Rec=0.84971 F-score=0.83093 Pre_macro=0.85184 Rec_macro=0.85604 F-score_macro=0.85362
start_local_time: 2023-06-15-03-51 run over time: 2023-06-15-04-08 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.49449 train_acc=0.69658 valid_loss=0.46867 valid_acc=0.72473
epoch: 1 train_loss=0.42064 train_acc=0.75741 valid_loss=0.43631 valid_acc=0.74462
epoch: 2 train_loss=0.39931 train_acc=0.77861 valid_loss=0.41613 valid_acc=0.76654
epoch: 3 train_loss=0.38248 train_acc=0.79165 valid_loss=0.39938 valid_acc=0.77710
epoch: 4 train_loss=0.36828 train_acc=0.80286 valid_loss=0.39858 valid_acc=0.78522
epoch: 5 train_loss=0.36510 train_acc=0.80489 valid_loss=0.40622 valid_acc=0.78441
epoch: 6 train_loss=0.35881 train_acc=0.80733 valid_loss=0.39903 valid_acc=0.77954
epoch: 7 train_loss=0.35256 train_acc=0.81199 valid_loss=0.41077 valid_acc=0.75802
epoch: 8 train_loss=0.35097 train_acc=0.81235 valid_loss=0.40430 valid_acc=0.79131
epoch: 9 train_loss=0.33923 train_acc=0.82123 valid_loss=0.40716 valid_acc=0.79131
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.35566 accuracy=0.81615 Pre=0.79958 Rec=0.74067 F-score=0.76900 Pre_macro=0.81300 Rec_macro=0.80498 F-score_macro=0.80816
start_local_time: 2023-06-15-04-10 run over time: 2023-06-15-04-18 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.43497 train_acc=0.74254 valid_loss=0.36655 valid_acc=0.80471
epoch: 1 train_loss=0.33880 train_acc=0.82427 valid_loss=0.35398 valid_acc=0.82136
epoch: 2 train_loss=0.31897 train_acc=0.83614 valid_loss=0.34427 valid_acc=0.83069
epoch: 3 train_loss=0.30657 train_acc=0.84345 valid_loss=0.33686 valid_acc=0.82785
epoch: 4 train_loss=0.29523 train_acc=0.85080 valid_loss=0.33560 valid_acc=0.83475
epoch: 5 train_loss=0.28869 train_acc=0.85334 valid_loss=0.33147 valid_acc=0.82704
epoch: 6 train_loss=0.28033 train_acc=0.85938 valid_loss=0.32620 valid_acc=0.82623
epoch: 7 train_loss=0.27449 train_acc=0.86257 valid_loss=0.33707 valid_acc=0.83475
epoch: 8 train_loss=0.26636 train_acc=0.86835 valid_loss=0.32645 valid_acc=0.82826
epoch: 9 train_loss=0.26262 train_acc=0.86627 valid_loss=0.32447 valid_acc=0.83272
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.28021 accuracy=0.86364 Pre=0.83301 Rec=0.83792 F-score=0.83546 Pre_macro=0.85921 Rec_macro=0.85983 F-score_macro=0.85952
start_local_time: 2023-06-15-12-51 run over time: 2023-06-15-13-16 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.44757 train_acc=0.73432 valid_loss=0.39283 valid_acc=0.78644
epoch: 1 train_loss=0.34899 train_acc=0.81930 valid_loss=0.35636 valid_acc=0.81161
epoch: 2 train_loss=0.32459 train_acc=0.83056 valid_loss=0.34492 valid_acc=0.82257
epoch: 3 train_loss=0.31362 train_acc=0.84152 valid_loss=0.34119 valid_acc=0.82298
epoch: 4 train_loss=0.30161 train_acc=0.84690 valid_loss=0.35082 valid_acc=0.81527
epoch: 5 train_loss=0.29220 train_acc=0.85187 valid_loss=0.33492 valid_acc=0.82907
epoch: 6 train_loss=0.28655 train_acc=0.85527 valid_loss=0.34419 valid_acc=0.82420
epoch: 7 train_loss=0.27794 train_acc=0.85998 valid_loss=0.36234 valid_acc=0.80187
epoch: 8 train_loss=0.27006 train_acc=0.86587 valid_loss=0.35218 valid_acc=0.82460
epoch: 9 train_loss=0.26464 train_acc=0.86927 valid_loss=0.34540 valid_acc=0.81811
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-45 | Multi_Nums=2
epoch: 0 train_loss=0.43756 train_acc=0.73975 valid_loss=0.37481 valid_acc=0.80024
epoch: 1 train_loss=0.33856 train_acc=0.82594 valid_loss=0.35196 valid_acc=0.81527
epoch: 2 train_loss=0.31806 train_acc=0.83487 valid_loss=0.33802 valid_acc=0.82907
epoch: 3 train_loss=0.30789 train_acc=0.84228 valid_loss=0.34339 valid_acc=0.82745
epoch: 4 train_loss=0.29777 train_acc=0.85070 valid_loss=0.34177 valid_acc=0.82907
epoch: 5 train_loss=0.28772 train_acc=0.85314 valid_loss=0.33603 valid_acc=0.83272
epoch: 6 train_loss=0.28076 train_acc=0.85755 valid_loss=0.34170 valid_acc=0.81973
epoch: 7 train_loss=0.26982 train_acc=0.86430 valid_loss=0.32649 valid_acc=0.82542
epoch: 8 train_loss=0.26354 train_acc=0.86977 valid_loss=0.34129 valid_acc=0.82542
epoch: 9 train_loss=0.26077 train_acc=0.87114 valid_loss=0.33311 valid_acc=0.82826
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.28786 accuracy=0.85308 Pre=0.81238 Rec=0.83792 F-score=0.82495 Pre_macro=0.84785 Rec_macro=0.85084 F-score_macro=0.84919
start_local_time: 2023-06-15-13-23 run over time: 2023-06-15-14-13 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.42434 train_acc=0.74792 valid_loss=0.36825 valid_acc=0.80512
epoch: 1 train_loss=0.33521 train_acc=0.82488 valid_loss=0.37553 valid_acc=0.80146
epoch: 2 train_loss=0.31462 train_acc=0.83802 valid_loss=0.34709 valid_acc=0.82704
epoch: 3 train_loss=0.30771 train_acc=0.84309 valid_loss=0.33478 valid_acc=0.83435
epoch: 4 train_loss=0.29550 train_acc=0.84994 valid_loss=0.33664 valid_acc=0.82988
epoch: 5 train_loss=0.28475 train_acc=0.85496 valid_loss=0.34528 valid_acc=0.81892
epoch: 6 train_loss=0.27736 train_acc=0.85978 valid_loss=0.32986 valid_acc=0.83313
epoch: 7 train_loss=0.26947 train_acc=0.86526 valid_loss=0.31673 valid_acc=0.83557
epoch: 8 train_loss=0.25974 train_acc=0.86967 valid_loss=0.36376 valid_acc=0.81161
epoch: 9 train_loss=0.25343 train_acc=0.87490 valid_loss=0.33756 valid_acc=0.82866
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.29084 accuracy=0.85836 Pre=0.79946 Rec=0.87721 F-score=0.83653 Pre_macro=0.85333 Rec_macro=0.86115 F-score_macro=0.85579
start_local_time: 2023-06-15-14-38 run over time: 2023-06-15-15-00 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.43510 train_acc=0.74092 valid_loss=0.37368 valid_acc=0.79862
epoch: 1 train_loss=0.33814 train_acc=0.82447 valid_loss=0.34961 valid_acc=0.82136
epoch: 2 train_loss=0.31927 train_acc=0.83573 valid_loss=0.33882 valid_acc=0.81730
epoch: 3 train_loss=0.30568 train_acc=0.84233 valid_loss=0.32973 valid_acc=0.82785
epoch: 4 train_loss=0.29771 train_acc=0.84608 valid_loss=0.32968 valid_acc=0.83029
epoch: 5 train_loss=0.28910 train_acc=0.85374 valid_loss=0.33693 valid_acc=0.82257
epoch: 6 train_loss=0.28056 train_acc=0.85821 valid_loss=0.33329 valid_acc=0.82623
epoch: 7 train_loss=0.27684 train_acc=0.86059 valid_loss=0.32674 valid_acc=0.82785
epoch: 8 train_loss=0.27010 train_acc=0.86556 valid_loss=0.32851 valid_acc=0.82745
epoch: 9 train_loss=0.26319 train_acc=0.86942 valid_loss=0.33731 valid_acc=0.81689
epoch: 10 train_loss=0.25132 train_acc=0.87601 valid_loss=0.32378 valid_acc=0.83110
epoch: 11 train_loss=0.25019 train_acc=0.87591 valid_loss=0.34548 valid_acc=0.82257
epoch: 12 train_loss=0.23812 train_acc=0.88307 valid_loss=0.33838 valid_acc=0.83029
epoch: 13 train_loss=0.23480 train_acc=0.88474 valid_loss=0.34302 valid_acc=0.83110
epoch: 14 train_loss=0.22383 train_acc=0.88926 valid_loss=0.36002 valid_acc=0.82623
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=15 loss=0.30323 accuracy=0.85755 Pre=0.85366 Rec=0.79077 F-score=0.82101 Pre_macro=0.85681 Rec_macro=0.84767 F-score_macro=0.85135
start_local_time: 2023-06-15-15-13 run over time: 2023-06-15-15-51 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.58741 train_acc=0.57696 valid_loss=0.57403 valid_acc=0.58262
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.58666 train_acc=0.57194 valid_loss=0.62578 valid_acc=0.56638
epoch: 1 train_loss=0.57354 train_acc=0.59892 valid_loss=0.55625 valid_acc=0.56679
epoch: 2 train_loss=0.56688 train_acc=0.60856 valid_loss=0.55079 valid_acc=0.64718
epoch: 3 train_loss=0.56781 train_acc=0.62120 valid_loss=0.53108 valid_acc=0.66667
epoch: 4 train_loss=0.54330 train_acc=0.64798 valid_loss=0.55531 valid_acc=0.68088
epoch: 5 train_loss=0.53642 train_acc=0.65803 valid_loss=0.51999 valid_acc=0.68413
epoch: 6 train_loss=0.53101 train_acc=0.65843 valid_loss=0.54821 valid_acc=0.68088
epoch: 7 train_loss=0.52730 train_acc=0.66543 valid_loss=0.51541 valid_acc=0.68250
epoch: 8 train_loss=0.52155 train_acc=0.67639 valid_loss=0.51840 valid_acc=0.69143
epoch: 9 train_loss=0.52183 train_acc=0.67588 valid_loss=0.54122 valid_acc=0.67641
epoch: 10 train_loss=0.52206 train_acc=0.67324 valid_loss=0.51786 valid_acc=0.70280
epoch: 11 train_loss=0.51629 train_acc=0.67558 valid_loss=0.54527 valid_acc=0.69752
epoch: 12 train_loss=0.51813 train_acc=0.67725 valid_loss=0.52188 valid_acc=0.68250
epoch: 13 train_loss=0.51415 train_acc=0.68334 valid_loss=0.50435 valid_acc=0.70686
epoch: 14 train_loss=0.51363 train_acc=0.68410 valid_loss=0.52736 valid_acc=0.69590
learning rate=0.00015 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.57392 train_acc=0.59755 valid_loss=0.52751 valid_acc=0.66951
epoch: 1 train_loss=0.54449 train_acc=0.64626 valid_loss=0.52202 valid_acc=0.68372
epoch: 2 train_loss=0.54115 train_acc=0.65534 valid_loss=0.58812 valid_acc=0.67885
epoch: 3 train_loss=0.53279 train_acc=0.66046 valid_loss=0.52273 valid_acc=0.68575
epoch: 4 train_loss=0.53117 train_acc=0.66599 valid_loss=0.52973 valid_acc=0.69549
epoch: 5 train_loss=0.52763 train_acc=0.66416 valid_loss=0.51466 valid_acc=0.69346
epoch: 6 train_loss=0.52390 train_acc=0.67030 valid_loss=0.51213 valid_acc=0.69184
epoch: 7 train_loss=0.51877 train_acc=0.67558 valid_loss=0.51872 valid_acc=0.69306
epoch: 8 train_loss=0.51675 train_acc=0.67680 valid_loss=0.52538 valid_acc=0.67600
epoch: 9 train_loss=0.51960 train_acc=0.67335 valid_loss=0.52527 valid_acc=0.67600
epoch: 10 train_loss=0.51254 train_acc=0.68192 valid_loss=0.52856 valid_acc=0.70199
epoch: 11 train_loss=0.51304 train_acc=0.68202 valid_loss=0.52027 valid_acc=0.68940
epoch: 12 train_loss=0.51189 train_acc=0.67847 valid_loss=0.50011 valid_acc=0.70280
epoch: 13 train_loss=0.51419 train_acc=0.68131 valid_loss=0.53188 valid_acc=0.68656
epoch: 14 train_loss=0.50754 train_acc=0.68887 valid_loss=0.51703 valid_acc=0.68250
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=15 loss=0.49691 accuracy=0.69399 Pre=0.59538 Rec=0.80943 F-score=0.68609 Pre_macro=0.70787 Rec_macro=0.71108 F-score_macro=0.69380
start_local_time: 2023-06-22-17-30 run over time: 2023-06-22-17-57 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.58075 train_acc=0.58330 valid_loss=0.57414 valid_acc=0.64677
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.56597 train_acc=0.60795 valid_loss=0.53335 valid_acc=0.67194
epoch: 1 train_loss=0.53852 train_acc=0.64697 valid_loss=0.53776 valid_acc=0.68413
epoch: 2 train_loss=0.53199 train_acc=0.66026 valid_loss=0.53122 valid_acc=0.67641
epoch: 3 train_loss=0.52919 train_acc=0.66041 valid_loss=0.52680 valid_acc=0.68737
epoch: 4 train_loss=0.52734 train_acc=0.65995 valid_loss=0.51471 valid_acc=0.69874
epoch: 5 train_loss=0.52663 train_acc=0.66016 valid_loss=0.51053 valid_acc=0.69509
epoch: 6 train_loss=0.52503 train_acc=0.66016 valid_loss=0.51251 valid_acc=0.69955
epoch: 7 train_loss=0.52416 train_acc=0.66406 valid_loss=0.54240 valid_acc=0.69468
epoch: 8 train_loss=0.52536 train_acc=0.66142 valid_loss=0.52421 valid_acc=0.66585
epoch: 9 train_loss=0.52036 train_acc=0.66315 valid_loss=0.51872 valid_acc=0.69793
epoch: 10 train_loss=0.52004 train_acc=0.67071 valid_loss=0.52403 valid_acc=0.69915
epoch: 11 train_loss=0.51855 train_acc=0.66528 valid_loss=0.52857 valid_acc=0.67763
epoch: 12 train_loss=0.52658 train_acc=0.66518 valid_loss=0.52990 valid_acc=0.68697
epoch: 13 train_loss=0.51996 train_acc=0.66513 valid_loss=0.52137 valid_acc=0.70361
epoch: 14 train_loss=0.51205 train_acc=0.67350 valid_loss=0.53141 valid_acc=0.68737
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=15 loss=0.51323 accuracy=0.69805 Pre=0.68767 Rec=0.49312 F-score=0.57437 Pre_macro=0.69505 Rec_macro=0.66772 F-score_macro=0.67020
start_local_time: 2023-06-22-18-06 run over time: 2023-06-22-18-18 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.01 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.56536 train_acc=0.60927 valid_loss=0.56097 valid_acc=0.67032
epoch: 1 train_loss=0.54064 train_acc=0.64910 valid_loss=0.54078 valid_acc=0.67763
epoch: 2 train_loss=0.54018 train_acc=0.65666 valid_loss=0.54516 valid_acc=0.67966
epoch: 3 train_loss=0.52907 train_acc=0.67025 valid_loss=0.53227 valid_acc=0.68656
epoch: 4 train_loss=0.53294 train_acc=0.66980 valid_loss=0.54071 valid_acc=0.68697
epoch: 5 train_loss=0.52470 train_acc=0.67213 valid_loss=0.54146 valid_acc=0.66261
epoch: 6 train_loss=0.52547 train_acc=0.66929 valid_loss=0.55705 valid_acc=0.67682
epoch: 7 train_loss=0.52610 train_acc=0.67096 valid_loss=0.54315 valid_acc=0.69387
epoch: 8 train_loss=0.52294 train_acc=0.66929 valid_loss=0.53058 valid_acc=0.69549
epoch: 9 train_loss=0.52340 train_acc=0.66746 valid_loss=0.53159 valid_acc=0.70321
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.49970 accuracy=0.71226 Pre=0.64928 Rec=0.66012 F-score=0.65465 Pre_macro=0.70357 Rec_macro=0.70454 F-score_macro=0.70402
start_local_time: 2023-06-22-18-54 run over time: 2023-06-22-19-02 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.05 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.0002 | fc dropout=0.05 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.0002 | fc dropout=0.05 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.0002 | fc dropout=0.05 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.0002 | fc dropout=0.05 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.57822 train_acc=0.57883 valid_loss=0.56504 valid_acc=0.65489
epoch: 1 train_loss=0.54178 train_acc=0.63126 valid_loss=0.52764 valid_acc=0.68737
epoch: 2 train_loss=0.53350 train_acc=0.64278 valid_loss=0.52572 valid_acc=0.68128
epoch: 3 train_loss=0.52878 train_acc=0.64218 valid_loss=0.51796 valid_acc=0.68413
epoch: 4 train_loss=0.52041 train_acc=0.65315 valid_loss=0.52428 valid_acc=0.68819
epoch: 5 train_loss=0.52283 train_acc=0.65234 valid_loss=0.52213 valid_acc=0.68737
epoch: 6 train_loss=0.51725 train_acc=0.65775 valid_loss=0.53805 valid_acc=0.68088
epoch: 7 train_loss=0.51833 train_acc=0.66056 valid_loss=0.51413 valid_acc=0.70321
epoch: 8 train_loss=0.51609 train_acc=0.66246 valid_loss=0.52008 valid_acc=0.70402
epoch: 9 train_loss=0.50919 train_acc=0.66587 valid_loss=0.51758 valid_acc=0.70361
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.49960 accuracy=0.71388 Pre=0.64976 Rec=0.66699 F-score=0.65826 Pre_macro=0.70543 Rec_macro=0.70694 F-score_macro=0.70610
start_local_time: 2023-06-22-19-18 run over time: 2023-06-22-19-25 ---------------this program run over----------------
learning rate=0.0001 | fc dropout=0.05 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.58779 train_acc=0.56050 valid_loss=0.57276 valid_acc=0.61510
epoch: 1 train_loss=0.55370 train_acc=0.62420 valid_loss=0.55255 valid_acc=0.67397
epoch: 2 train_loss=0.53531 train_acc=0.65014 valid_loss=0.52850 valid_acc=0.68047
epoch: 3 train_loss=0.52836 train_acc=0.65830 valid_loss=0.51916 valid_acc=0.67113
epoch: 4 train_loss=0.51165 train_acc=0.66722 valid_loss=0.52287 valid_acc=0.69468
epoch: 5 train_loss=0.49327 train_acc=0.68440 valid_loss=0.47989 valid_acc=0.73691
epoch: 6 train_loss=0.47044 train_acc=0.70042 valid_loss=0.48969 valid_acc=0.76411
epoch: 7 train_loss=0.44952 train_acc=0.72281 valid_loss=0.47618 valid_acc=0.73853
epoch: 8 train_loss=0.44012 train_acc=0.73438 valid_loss=0.58064 valid_acc=0.68697
epoch: 9 train_loss=0.43960 train_acc=0.73858 valid_loss=0.50519 valid_acc=0.75883
epoch: 10 train_loss=0.43642 train_acc=0.73658 valid_loss=0.48225 valid_acc=0.75721
epoch: 11 train_loss=0.42926 train_acc=0.74579 valid_loss=0.48870 valid_acc=0.75680
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=12 loss=0.44685 accuracy=0.76664 Pre=0.83612 Rec=0.54126 F-score=0.65713 Pre_macro=0.78869 Rec_macro=0.73328 F-score_macro=0.74013
start_local_time: 2023-06-22-19-26 run over time: 2023-06-22-19-35 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.05 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.0002 | fc dropout=0.05 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.0002 | fc dropout=0.05 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.0002 | fc dropout=0.05 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.0002 | fc dropout=0.05 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.0002 | fc dropout=0.05 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.58874 train_acc=0.56915 valid_loss=0.58884 valid_acc=0.57247
epoch: 1 train_loss=0.58848 train_acc=0.56915 valid_loss=0.59537 valid_acc=0.57247
epoch: 2 train_loss=0.58886 train_acc=0.56915 valid_loss=0.58755 valid_acc=0.57247
epoch: 3 train_loss=0.58852 train_acc=0.56915 valid_loss=0.58689 valid_acc=0.57247
epoch: 4 train_loss=0.58836 train_acc=0.56915 valid_loss=0.58625 valid_acc=0.57247
epoch: 5 train_loss=0.58850 train_acc=0.56915 valid_loss=0.58834 valid_acc=0.57247
epoch: 6 train_loss=0.58829 train_acc=0.56915 valid_loss=0.58835 valid_acc=0.57247
epoch: 7 train_loss=0.58833 train_acc=0.56915 valid_loss=0.58821 valid_acc=0.57247
epoch: 8 train_loss=0.58826 train_acc=0.56915 valid_loss=0.58696 valid_acc=0.57247
epoch: 9 train_loss=0.58819 train_acc=0.56915 valid_loss=0.58687 valid_acc=0.57247
epoch: 10 train_loss=0.58818 train_acc=0.56915 valid_loss=0.58720 valid_acc=0.57247
epoch: 11 train_loss=0.58821 train_acc=0.56915 valid_loss=0.58682 valid_acc=0.57247
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.58137 train_acc=0.57904 valid_loss=0.55035 valid_acc=0.65002
epoch: 1 train_loss=0.55328 train_acc=0.63144 valid_loss=0.56372 valid_acc=0.68331
epoch: 2 train_loss=0.54006 train_acc=0.65716 valid_loss=0.58751 valid_acc=0.68453
epoch: 3 train_loss=0.53380 train_acc=0.66624 valid_loss=0.51776 valid_acc=0.68372
epoch: 4 train_loss=0.52978 train_acc=0.66908 valid_loss=0.52766 valid_acc=0.68778
epoch: 5 train_loss=0.52931 train_acc=0.66863 valid_loss=0.54841 valid_acc=0.69793
epoch: 6 train_loss=0.52273 train_acc=0.67867 valid_loss=0.52120 valid_acc=0.69346
epoch: 7 train_loss=0.52176 train_acc=0.67157 valid_loss=0.51633 valid_acc=0.69671
epoch: 8 train_loss=0.52200 train_acc=0.67162 valid_loss=0.51192 valid_acc=0.70037
epoch: 9 train_loss=0.51726 train_acc=0.67614 valid_loss=0.52297 valid_acc=0.69387
epoch: 10 train_loss=0.51436 train_acc=0.68106 valid_loss=0.52167 valid_acc=0.70361
epoch: 11 train_loss=0.51025 train_acc=0.68385 valid_loss=0.52083 valid_acc=0.70199
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=12 loss=0.50414 accuracy=0.70779 Pre=0.65919 Rec=0.60609 F-score=0.63153 Pre_macro=0.69838 Rec_macro=0.69274 F-score_macro=0.69471
start_local_time: 2023-06-23-13-40 run over time: 2023-06-23-13-50 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.50457 train_acc=0.68684 valid_loss=0.46842 valid_acc=0.72148
epoch: 1 train_loss=0.42675 train_acc=0.75629 valid_loss=0.42653 valid_acc=0.76167
epoch: 2 train_loss=0.40252 train_acc=0.77684 valid_loss=0.40042 valid_acc=0.77548
epoch: 3 train_loss=0.38082 train_acc=0.79312 valid_loss=0.40365 valid_acc=0.78522
epoch: 4 train_loss=0.36947 train_acc=0.80038 valid_loss=0.41207 valid_acc=0.76654
epoch: 5 train_loss=0.36403 train_acc=0.80636 valid_loss=0.40595 valid_acc=0.77345
epoch: 6 train_loss=0.36022 train_acc=0.80717 valid_loss=0.39267 valid_acc=0.78603
epoch: 7 train_loss=0.34770 train_acc=0.81767 valid_loss=0.39122 valid_acc=0.79091
epoch: 8 train_loss=0.34433 train_acc=0.81904 valid_loss=0.37520 valid_acc=0.79618
epoch: 9 train_loss=0.34104 train_acc=0.81879 valid_loss=0.41173 valid_acc=0.77670
epoch: 10 train_loss=0.33677 train_acc=0.82397 valid_loss=0.38050 valid_acc=0.79821
epoch: 11 train_loss=0.33962 train_acc=0.82138 valid_loss=0.38117 valid_acc=0.80065
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=12 loss=0.35211 accuracy=0.81494 Pre=0.77657 Rec=0.77505 F-score=0.77581 Pre_macro=0.80921 Rec_macro=0.80903 F-score_macro=0.80912
start_local_time: 2023-06-23-14-04 run over time: 2023-06-23-14-13 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.58663 train_acc=0.57275 valid_loss=0.55861 valid_acc=0.65002
epoch: 1 train_loss=0.55133 train_acc=0.63809 valid_loss=0.53032 valid_acc=0.67235
epoch: 2 train_loss=0.53597 train_acc=0.65229 valid_loss=0.53485 valid_acc=0.67600
epoch: 3 train_loss=0.52100 train_acc=0.66107 valid_loss=0.48938 valid_acc=0.70889
epoch: 4 train_loss=0.49073 train_acc=0.68968 valid_loss=0.49431 valid_acc=0.71336
epoch: 5 train_loss=0.47079 train_acc=0.71545 valid_loss=0.44760 valid_acc=0.75680
epoch: 6 train_loss=0.45707 train_acc=0.71961 valid_loss=0.45167 valid_acc=0.76005
epoch: 7 train_loss=0.44211 train_acc=0.73727 valid_loss=0.44779 valid_acc=0.77670
epoch: 8 train_loss=0.43663 train_acc=0.74280 valid_loss=0.45484 valid_acc=0.78035
epoch: 9 train_loss=0.42938 train_acc=0.75046 valid_loss=0.41534 valid_acc=0.76979
epoch: 10 train_loss=0.42577 train_acc=0.75198 valid_loss=0.42260 valid_acc=0.78482
epoch: 11 train_loss=0.42356 train_acc=0.75396 valid_loss=0.43369 valid_acc=0.77060
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=12 loss=0.40552 accuracy=0.79058 Pre=0.71864 Rec=0.81041 F-score=0.76177 Pre_macro=0.78599 Rec_macro=0.79352 F-score_macro=0.78748
start_local_time: 2023-06-23-14-15 run over time: 2023-06-23-14-24 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.56586 train_acc=0.61135 valid_loss=0.53739 valid_acc=0.67316
epoch: 1 train_loss=0.53208 train_acc=0.66021 valid_loss=0.54323 valid_acc=0.68413
epoch: 2 train_loss=0.52620 train_acc=0.66462 valid_loss=0.56185 valid_acc=0.67438
epoch: 3 train_loss=0.52314 train_acc=0.67091 valid_loss=0.53142 valid_acc=0.69468
epoch: 4 train_loss=0.52162 train_acc=0.67324 valid_loss=0.52259 valid_acc=0.70037
epoch: 5 train_loss=0.51367 train_acc=0.68004 valid_loss=0.51065 valid_acc=0.69996
epoch: 6 train_loss=0.51444 train_acc=0.67862 valid_loss=0.51097 valid_acc=0.69915
epoch: 7 train_loss=0.51164 train_acc=0.68035 valid_loss=0.51946 valid_acc=0.67438
epoch: 8 train_loss=0.50727 train_acc=0.68887 valid_loss=0.50739 valid_acc=0.70605
epoch: 9 train_loss=0.50690 train_acc=0.68567 valid_loss=0.55135 valid_acc=0.70686
epoch: 10 train_loss=0.50653 train_acc=0.68461 valid_loss=0.49506 valid_acc=0.71255
epoch: 11 train_loss=0.49862 train_acc=0.69415 valid_loss=0.51813 valid_acc=0.71417
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=12 loss=0.49682 accuracy=0.71794 Pre=0.65604 Rec=0.66699 F-score=0.66147 Pre_macro=0.70940 Rec_macro=0.71040 F-score_macro=0.70987
start_local_time: 2023-06-23-14-27 run over time: 2023-06-23-14-36 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.56404 train_acc=0.61003 valid_loss=0.55330 valid_acc=0.63500
epoch: 1 train_loss=0.53193 train_acc=0.65031 valid_loss=0.52640 valid_acc=0.68331
epoch: 2 train_loss=0.52089 train_acc=0.66406 valid_loss=0.51622 valid_acc=0.68534
epoch: 3 train_loss=0.52931 train_acc=0.64935 valid_loss=0.54196 valid_acc=0.66910
epoch: 4 train_loss=0.51661 train_acc=0.66599 valid_loss=0.49965 valid_acc=0.70727
epoch: 5 train_loss=0.48983 train_acc=0.69318 valid_loss=0.47133 valid_acc=0.74218
epoch: 6 train_loss=0.47025 train_acc=0.71160 valid_loss=0.47882 valid_acc=0.76167
epoch: 7 train_loss=0.45864 train_acc=0.72606 valid_loss=0.44592 valid_acc=0.77060
epoch: 8 train_loss=0.43519 train_acc=0.74488 valid_loss=0.43850 valid_acc=0.77182
epoch: 9 train_loss=0.43164 train_acc=0.74442 valid_loss=0.41284 valid_acc=0.77426
epoch: 10 train_loss=0.42201 train_acc=0.75944 valid_loss=0.41185 valid_acc=0.77020
epoch: 11 train_loss=0.42400 train_acc=0.75132 valid_loss=0.43230 valid_acc=0.77710
learning rate=0.0002 | fc dropout=0.3 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.56512 train_acc=0.61496 valid_loss=0.56117 valid_acc=0.65286
epoch: 1 train_loss=0.53379 train_acc=0.66000 valid_loss=0.55616 valid_acc=0.68128
epoch: 2 train_loss=0.52557 train_acc=0.66888 valid_loss=0.54974 valid_acc=0.66058
epoch: 3 train_loss=0.52291 train_acc=0.67583 valid_loss=0.54795 valid_acc=0.69671
epoch: 4 train_loss=0.51166 train_acc=0.68268 valid_loss=0.49797 valid_acc=0.70321
epoch: 5 train_loss=0.48630 train_acc=0.70434 valid_loss=0.46707 valid_acc=0.74462
epoch: 6 train_loss=0.47009 train_acc=0.71733 valid_loss=0.43794 valid_acc=0.75477
epoch: 7 train_loss=0.44644 train_acc=0.74371 valid_loss=0.42836 valid_acc=0.76045
epoch: 8 train_loss=0.43553 train_acc=0.75309 valid_loss=0.41716 valid_acc=0.78035
epoch: 9 train_loss=0.43674 train_acc=0.75096 valid_loss=0.43339 valid_acc=0.76979
epoch: 10 train_loss=0.41711 train_acc=0.76679 valid_loss=0.42367 valid_acc=0.76857
epoch: 11 train_loss=0.42199 train_acc=0.76334 valid_loss=0.41513 valid_acc=0.77467
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=12 loss=0.36908 accuracy=0.80073 Pre=0.74241 Rec=0.79273 F-score=0.76675 Pre_macro=0.79459 Rec_macro=0.79955 F-score_macro=0.79641
start_local_time: 2023-06-23-14-38 run over time: 2023-06-23-14-56 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.56958 train_acc=0.60993 valid_loss=0.54616 valid_acc=0.66829
epoch: 1 train_loss=0.53291 train_acc=0.66016 valid_loss=0.54468 valid_acc=0.67885
epoch: 2 train_loss=0.52905 train_acc=0.66959 valid_loss=0.53161 valid_acc=0.68169
epoch: 3 train_loss=0.52445 train_acc=0.67000 valid_loss=0.53159 valid_acc=0.69549
epoch: 4 train_loss=0.51251 train_acc=0.67456 valid_loss=0.50473 valid_acc=0.69874
epoch: 5 train_loss=0.49112 train_acc=0.69623 valid_loss=0.50208 valid_acc=0.70077
epoch: 6 train_loss=0.48747 train_acc=0.70247 valid_loss=0.44535 valid_acc=0.74706
epoch: 7 train_loss=0.45880 train_acc=0.72433 valid_loss=0.47835 valid_acc=0.74543
epoch: 8 train_loss=0.45247 train_acc=0.73321 valid_loss=0.50192 valid_acc=0.74015
epoch: 9 train_loss=0.44333 train_acc=0.73904 valid_loss=0.42238 valid_acc=0.76857
epoch: 10 train_loss=0.43147 train_acc=0.74782 valid_loss=0.44841 valid_acc=0.77629
epoch: 11 train_loss=0.42414 train_acc=0.75325 valid_loss=0.45400 valid_acc=0.75355
learning rate=0.0002 | fc dropout=0.4 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.56706 train_acc=0.61009 valid_loss=0.55855 valid_acc=0.67560
epoch: 1 train_loss=0.53923 train_acc=0.65559 valid_loss=0.52181 valid_acc=0.67966
epoch: 2 train_loss=0.52892 train_acc=0.66569 valid_loss=0.54035 valid_acc=0.69062
epoch: 3 train_loss=0.52420 train_acc=0.66969 valid_loss=0.53063 valid_acc=0.67154
epoch: 4 train_loss=0.52064 train_acc=0.67451 valid_loss=0.51932 valid_acc=0.69631
epoch: 5 train_loss=0.51873 train_acc=0.67776 valid_loss=0.51656 valid_acc=0.69915
epoch: 6 train_loss=0.51478 train_acc=0.67756 valid_loss=0.50625 valid_acc=0.70361
epoch: 7 train_loss=0.51118 train_acc=0.68380 valid_loss=0.51838 valid_acc=0.70037
epoch: 8 train_loss=0.50441 train_acc=0.68583 valid_loss=0.55091 valid_acc=0.68453
epoch: 9 train_loss=0.50938 train_acc=0.68410 valid_loss=0.51802 valid_acc=0.69468
epoch: 10 train_loss=0.50677 train_acc=0.68922 valid_loss=0.51633 valid_acc=0.71173
epoch: 11 train_loss=0.50626 train_acc=0.69044 valid_loss=0.50821 valid_acc=0.70483
learning rate=0.00015 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.56450 train_acc=0.61744 valid_loss=0.53948 valid_acc=0.65773
epoch: 1 train_loss=0.53406 train_acc=0.66939 valid_loss=0.53426 valid_acc=0.67154
epoch: 2 train_loss=0.52507 train_acc=0.67766 valid_loss=0.51957 valid_acc=0.69143
epoch: 3 train_loss=0.51271 train_acc=0.68380 valid_loss=0.53654 valid_acc=0.68291
epoch: 4 train_loss=0.50734 train_acc=0.67776 valid_loss=0.47636 valid_acc=0.72757
epoch: 5 train_loss=0.47328 train_acc=0.72124 valid_loss=0.46075 valid_acc=0.74706
epoch: 6 train_loss=0.45560 train_acc=0.73443 valid_loss=0.46274 valid_acc=0.75030
epoch: 7 train_loss=0.43985 train_acc=0.74777 valid_loss=0.41766 valid_acc=0.77588
epoch: 8 train_loss=0.43014 train_acc=0.75350 valid_loss=0.41540 valid_acc=0.76857
epoch: 9 train_loss=0.42674 train_acc=0.75325 valid_loss=0.47880 valid_acc=0.77182
epoch: 10 train_loss=0.42137 train_acc=0.75933 valid_loss=0.44744 valid_acc=0.74300
epoch: 11 train_loss=0.42193 train_acc=0.75873 valid_loss=0.43858 valid_acc=0.77426
learning rate=0.00015 | fc dropout=0.4 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.56345 train_acc=0.61653 valid_loss=0.53934 valid_acc=0.67925
epoch: 1 train_loss=0.53324 train_acc=0.66087 valid_loss=0.52331 valid_acc=0.68859
epoch: 2 train_loss=0.52551 train_acc=0.67051 valid_loss=0.54367 valid_acc=0.67276
epoch: 3 train_loss=0.52254 train_acc=0.67685 valid_loss=0.52669 valid_acc=0.68940
epoch: 4 train_loss=0.51487 train_acc=0.67746 valid_loss=0.52357 valid_acc=0.68737
epoch: 5 train_loss=0.51689 train_acc=0.67685 valid_loss=0.50055 valid_acc=0.70361
epoch: 6 train_loss=0.51682 train_acc=0.67964 valid_loss=0.51076 valid_acc=0.68940
epoch: 7 train_loss=0.51188 train_acc=0.68522 valid_loss=0.51252 valid_acc=0.70280
epoch: 8 train_loss=0.50587 train_acc=0.68725 valid_loss=0.50306 valid_acc=0.70240
epoch: 9 train_loss=0.50938 train_acc=0.68496 valid_loss=0.50562 valid_acc=0.71255
epoch: 10 train_loss=0.50316 train_acc=0.68928 valid_loss=0.51007 valid_acc=0.68453
epoch: 11 train_loss=0.50461 train_acc=0.68562 valid_loss=0.51519 valid_acc=0.69915
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=12 loss=0.49161 accuracy=0.70536 Pre=0.69837 Rec=0.50491 F-score=0.58609 Pre_macro=0.70335 Rec_macro=0.67569 F-score_macro=0.67868
start_local_time: 2023-06-23-14-58 run over time: 2023-06-23-15-35 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.56914 train_acc=0.61501 valid_loss=0.54872 valid_acc=0.66423
epoch: 1 train_loss=0.53715 train_acc=0.65173 valid_loss=0.52625 valid_acc=0.67885
epoch: 2 train_loss=0.52378 train_acc=0.66807 valid_loss=0.59452 valid_acc=0.59196
epoch: 3 train_loss=0.50460 train_acc=0.68471 valid_loss=0.46624 valid_acc=0.73244
epoch: 4 train_loss=0.48110 train_acc=0.69973 valid_loss=0.46188 valid_acc=0.74665
epoch: 5 train_loss=0.45743 train_acc=0.72195 valid_loss=0.61564 valid_acc=0.67276
epoch: 6 train_loss=0.44590 train_acc=0.73980 valid_loss=0.42162 valid_acc=0.76492
epoch: 7 train_loss=0.44488 train_acc=0.73488 valid_loss=0.48691 valid_acc=0.76736
epoch: 8 train_loss=0.43640 train_acc=0.74934 valid_loss=0.41543 valid_acc=0.76817
epoch: 9 train_loss=0.42058 train_acc=0.75725 valid_loss=0.40918 valid_acc=0.78685
epoch: 10 train_loss=0.42061 train_acc=0.75796 valid_loss=0.43648 valid_acc=0.77263
epoch: 11 train_loss=0.41667 train_acc=0.75822 valid_loss=0.41087 valid_acc=0.78482
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-06 | Multi_Nums=2
epoch: 0 train_loss=0.56334 train_acc=0.62652 valid_loss=0.54903 valid_acc=0.62769
epoch: 1 train_loss=0.53215 train_acc=0.67182 valid_loss=0.52563 valid_acc=0.68819
epoch: 2 train_loss=0.52765 train_acc=0.67948 valid_loss=0.54314 valid_acc=0.69509
epoch: 3 train_loss=0.53097 train_acc=0.67436 valid_loss=0.52261 valid_acc=0.69184
epoch: 4 train_loss=0.53376 train_acc=0.66985 valid_loss=0.52197 valid_acc=0.68413
epoch: 5 train_loss=0.51968 train_acc=0.68730 valid_loss=0.51136 valid_acc=0.70077
epoch: 6 train_loss=0.51553 train_acc=0.68770 valid_loss=0.51312 valid_acc=0.69915
epoch: 7 train_loss=0.49890 train_acc=0.70105 valid_loss=0.49635 valid_acc=0.72473
epoch: 8 train_loss=0.48211 train_acc=0.71327 valid_loss=0.49491 valid_acc=0.72026
epoch: 9 train_loss=0.46250 train_acc=0.72565 valid_loss=0.43698 valid_acc=0.75639
epoch: 10 train_loss=0.45133 train_acc=0.73407 valid_loss=0.42510 valid_acc=0.77060
epoch: 11 train_loss=0.43840 train_acc=0.74523 valid_loss=0.41864 valid_acc=0.76857
learning rate=0.0002 | fc dropout=0.4 |  weight decay=1e-65 | Multi_Nums=2
epoch: 0 train_loss=0.57143 train_acc=0.61009 valid_loss=0.56653 valid_acc=0.65043
epoch: 1 train_loss=0.53004 train_acc=0.65503 valid_loss=0.47707 valid_acc=0.71498
epoch: 2 train_loss=0.50864 train_acc=0.67791 valid_loss=0.48419 valid_acc=0.72107
epoch: 3 train_loss=0.47654 train_acc=0.70860 valid_loss=0.47871 valid_acc=0.74097
epoch: 4 train_loss=0.45424 train_acc=0.72469 valid_loss=0.43486 valid_acc=0.77791
epoch: 5 train_loss=0.43904 train_acc=0.74488 valid_loss=0.43254 valid_acc=0.76208
epoch: 6 train_loss=0.43941 train_acc=0.74112 valid_loss=0.41757 valid_acc=0.77832
epoch: 7 train_loss=0.42270 train_acc=0.75467 valid_loss=0.41632 valid_acc=0.76776
epoch: 8 train_loss=0.42295 train_acc=0.75512 valid_loss=0.41945 valid_acc=0.78319
epoch: 9 train_loss=0.41132 train_acc=0.76720 valid_loss=0.43511 valid_acc=0.76654
epoch: 10 train_loss=0.41810 train_acc=0.75771 valid_loss=0.42697 valid_acc=0.78928
epoch: 11 train_loss=0.41203 train_acc=0.76385 valid_loss=0.41460 valid_acc=0.77994
learning rate=0.0002 | fc dropout=0.4 |  weight decay=1e-06 | Multi_Nums=2
epoch: 0 train_loss=0.56713 train_acc=0.60740 valid_loss=0.52985 valid_acc=0.67682
epoch: 1 train_loss=0.53524 train_acc=0.67030 valid_loss=0.53945 valid_acc=0.68291
epoch: 2 train_loss=0.52656 train_acc=0.67664 valid_loss=0.52455 valid_acc=0.68291
epoch: 3 train_loss=0.52494 train_acc=0.68091 valid_loss=0.51549 valid_acc=0.69022
epoch: 4 train_loss=0.51931 train_acc=0.68633 valid_loss=0.51728 valid_acc=0.69022
epoch: 5 train_loss=0.51954 train_acc=0.68304 valid_loss=0.51337 valid_acc=0.69915
epoch: 6 train_loss=0.51809 train_acc=0.68791 valid_loss=0.50926 valid_acc=0.69143
epoch: 7 train_loss=0.51335 train_acc=0.69288 valid_loss=0.51575 valid_acc=0.68778
epoch: 8 train_loss=0.51390 train_acc=0.69303 valid_loss=0.51095 valid_acc=0.70361
epoch: 9 train_loss=0.50674 train_acc=0.69836 valid_loss=0.52092 valid_acc=0.70077
epoch: 10 train_loss=0.50657 train_acc=0.69907 valid_loss=0.51209 valid_acc=0.70483
epoch: 11 train_loss=0.50656 train_acc=0.69836 valid_loss=0.51991 valid_acc=0.70849
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=12 loss=0.49359 accuracy=0.71916 Pre=0.64399 Rec=0.71611 F-score=0.67814 Pre_macro=0.71351 Rec_macro=0.71871 F-score_macro=0.71452
start_local_time: 2023-06-23-15-39 run over time: 2023-06-23-16-16 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=3
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=3
epoch: 0 train_loss=0.58078 train_acc=0.58513 valid_loss=0.57472 valid_acc=0.65855
epoch: 1 train_loss=0.56181 train_acc=0.61156 valid_loss=0.57360 valid_acc=0.55664
epoch: 2 train_loss=0.54721 train_acc=0.62566 valid_loss=0.59829 valid_acc=0.67803
epoch: 3 train_loss=0.54064 train_acc=0.64311 valid_loss=0.51937 valid_acc=0.68819
epoch: 4 train_loss=0.53436 train_acc=0.64316 valid_loss=0.52163 valid_acc=0.68331
epoch: 5 train_loss=0.53582 train_acc=0.64098 valid_loss=0.52802 valid_acc=0.69103
epoch: 6 train_loss=0.52746 train_acc=0.64519 valid_loss=0.52838 valid_acc=0.68210
epoch: 7 train_loss=0.52463 train_acc=0.65173 valid_loss=0.55446 valid_acc=0.68859
epoch: 8 train_loss=0.52559 train_acc=0.64808 valid_loss=0.51583 valid_acc=0.69265
epoch: 9 train_loss=0.52261 train_acc=0.65564 valid_loss=0.51979 valid_acc=0.69955
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-06 | Multi_Nums=3
epoch: 0 train_loss=0.57433 train_acc=0.60024 valid_loss=0.55411 valid_acc=0.65895
epoch: 1 train_loss=0.55103 train_acc=0.63824 valid_loss=0.54354 valid_acc=0.66870
epoch: 2 train_loss=0.54598 train_acc=0.65072 valid_loss=0.52651 valid_acc=0.68656
epoch: 3 train_loss=0.53598 train_acc=0.65655 valid_loss=0.53195 valid_acc=0.69184
epoch: 4 train_loss=0.53349 train_acc=0.65767 valid_loss=0.53291 valid_acc=0.68697
epoch: 5 train_loss=0.53257 train_acc=0.66071 valid_loss=0.51701 valid_acc=0.68250
epoch: 6 train_loss=0.52414 train_acc=0.66843 valid_loss=0.52153 valid_acc=0.67276
epoch: 7 train_loss=0.52796 train_acc=0.66898 valid_loss=0.51210 valid_acc=0.70037
epoch: 8 train_loss=0.52197 train_acc=0.67324 valid_loss=0.54381 valid_acc=0.69590
epoch: 9 train_loss=0.52602 train_acc=0.66782 valid_loss=0.51425 valid_acc=0.70361
learning_rate_list=0 fc_dropout_rate_list=0 train_epochs=10 loss=0.49164 accuracy=0.71144 Pre=0.63020 Rec=0.72986 F-score=0.67638 Pre_macro=0.70809 Rec_macro=0.71417 F-score_macro=0.70802
start_local_time: 2023-06-23-16-20 run over time: 2023-06-23-16-35 ---------------this program run over----------------
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=3
epoch: 0 train_loss=0.59095 train_acc=0.55996 valid_loss=0.56486 valid_acc=0.62119
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=3
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=3
epoch: 0 train_loss=0.58603 train_acc=0.57533 valid_loss=0.59083 valid_acc=0.61510
epoch: 1 train_loss=0.57256 train_acc=0.60780 valid_loss=0.54306 valid_acc=0.65367
epoch: 2 train_loss=0.55188 train_acc=0.63200 valid_loss=0.53629 valid_acc=0.67276
epoch: 3 train_loss=0.55161 train_acc=0.63296 valid_loss=0.54605 valid_acc=0.66423
epoch: 4 train_loss=0.54253 train_acc=0.64712 valid_loss=0.53047 valid_acc=0.67560
epoch: 5 train_loss=0.53517 train_acc=0.64859 valid_loss=0.52902 valid_acc=0.68534
epoch: 6 train_loss=0.52994 train_acc=0.65858 valid_loss=0.51660 valid_acc=0.68494
epoch: 7 train_loss=0.53106 train_acc=0.65524 valid_loss=0.52766 valid_acc=0.69062
epoch: 8 train_loss=0.53003 train_acc=0.66092 valid_loss=0.51170 valid_acc=0.68900
epoch: 9 train_loss=0.52651 train_acc=0.66097 valid_loss=0.52645 valid_acc=0.68981
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-06 | Multi_Nums=3
epoch: 0 train_loss=0.59093 train_acc=0.56539 valid_loss=0.57755 valid_acc=0.63337
epoch: 1 train_loss=0.58030 train_acc=0.59431 valid_loss=0.57235 valid_acc=0.64758
learning rate=0.0002 | fc dropout=0.25 |  weight decay=1e-65 | Multi_Nums=1
epoch: 0 train_loss=0.55604 train_acc=0.63504 valid_loss=0.51567 valid_acc=0.68128
epoch: 1 train_loss=0.50485 train_acc=0.68912 valid_loss=0.46668 valid_acc=0.71823
epoch: 2 train_loss=0.46581 train_acc=0.72712 valid_loss=0.47427 valid_acc=0.74909
epoch: 3 train_loss=0.43636 train_acc=0.75223 valid_loss=0.42976 valid_acc=0.76289
epoch: 4 train_loss=0.41902 train_acc=0.76684 valid_loss=0.44007 valid_acc=0.77791
epoch: 5 train_loss=0.41134 train_acc=0.77110 valid_loss=0.45347 valid_acc=0.76573
learning rate=0.0002 | fc dropout=0.2 |  weight decay=1e-65 | Multi_Nums=2